{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n"
      ],
      "metadata": {
        "id": "Koy1JAlfP2Xi"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/test.csv\")\n",
        "test_survived = pd.read_csv(\"/content/gender_submission.csv\")\n",
        "\n",
        "train_data.head(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "y86fOlM2QZRt",
        "outputId": "0c4d7e78-ffd6-4391-a54d-65f0d49e0038"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "5            6         0       3   \n",
              "6            7         0       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "5                                   Moran, Mr. James    male   NaN      0   \n",
              "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  \n",
              "5      0            330877   8.4583   NaN        Q  \n",
              "6      0             17463  51.8625   E46        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83a34c90-2f70-424d-b8c3-87abbfaec01e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83a34c90-2f70-424d-b8c3-87abbfaec01e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83a34c90-2f70-424d-b8c3-87abbfaec01e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83a34c90-2f70-424d-b8c3-87abbfaec01e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3d9cca9-8e9c-4eb6-80e4-eb68e474c12a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3d9cca9-8e9c-4eb6-80e4-eb68e474c12a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3d9cca9-8e9c-4eb6-80e4-eb68e474c12a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334042,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.6934285971809,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = train_data.replace(['female','male'],[0,1])\n",
        "train_data = train_data.replace(['S','C','Q'],[0,1,2])\n",
        "train_data.fillna(0, inplace=True)\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "2Zw6A2xiQ95p",
        "outputId": "e850bf77-17e1-4e0a-bcbd-40c2d4a880ab"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name  Sex   Age  SibSp  Parch  \\\n",
              "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
              "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
              "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
              "\n",
              "             Ticket     Fare Cabin  Embarked  \n",
              "0         A/5 21171   7.2500     0       0.0  \n",
              "1          PC 17599  71.2833   C85       1.0  \n",
              "2  STON/O2. 3101282   7.9250     0       0.0  \n",
              "3            113803  53.1000  C123       0.0  \n",
              "4            373450   8.0500     0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6b249e5-db26-42d6-b257-6f125f4428ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6b249e5-db26-42d6-b257-6f125f4428ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6b249e5-db26-42d6-b257-6f125f4428ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6b249e5-db26-42d6-b257-6f125f4428ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eca523da-2a13-4884-a8e2-3f7f1306384a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eca523da-2a13-4884-a8e2-3f7f1306384a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eca523da-2a13-4884-a8e2-3f7f1306384a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.596074065915875,\n        \"min\": 0.0,\n        \"max\": 80.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          59.0,\n          36.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.6934285971809,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"B101\",\n          \"A19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6356734677794962,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "y_train = train_data[['Survived']]\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(x_train.shape , y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WozPbl-FTdxy",
        "outputId": "1eb64894-60af-4c5e-9c80-a1038ba6a0be"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7) (891, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data.replace(['female', 'male'],[0,1])\n",
        "test_data = test_data.replace(['S','C','Q'],[0,1,2])\n",
        "test_data.fillna(0, inplace=True)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "dYKZFFjIqw3n",
        "outputId": "39b41aca-ada2-45f2-ccbb-61f8548417cb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Pclass                                          Name  Sex  \\\n",
              "0          892       3                              Kelly, Mr. James    1   \n",
              "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
              "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
              "3          895       3                              Wirz, Mr. Albert    1   \n",
              "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
              "\n",
              "    Age  SibSp  Parch   Ticket     Fare Cabin  Embarked  \n",
              "0  34.5      0      0   330911   7.8292     0         2  \n",
              "1  47.0      1      0   363272   7.0000     0         0  \n",
              "2  62.0      0      0   240276   9.6875     0         2  \n",
              "3  27.0      0      0   315154   8.6625     0         0  \n",
              "4  22.0      1      1  3101298  12.2875     0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42678253-52ed-4a12-8733-64c82fe57d9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>1</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42678253-52ed-4a12-8733-64c82fe57d9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42678253-52ed-4a12-8733-64c82fe57d9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42678253-52ed-4a12-8733-64c82fe57d9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5a885df-d2f3-4ab7-ae51-4d2389d8dd77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5a885df-d2f3-4ab7-ae51-4d2389d8dd77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5a885df-d2f3-4ab7-ae51-4d2389d8dd77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 418,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120,\n        \"min\": 892,\n        \"max\": 1309,\n        \"num_unique_values\": 418,\n        \"samples\": [\n          1213,\n          1216,\n          1280\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"Krekorian, Mr. Neshan\",\n          \"Kreuchen, Miss. Emilie\",\n          \"Canavan, Mr. Patrick\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.599608046928353,\n        \"min\": 0.0,\n        \"max\": 76.0,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          28.0,\n          34.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 363,\n        \"samples\": [\n          \"2673\",\n          \"W./C. 6607\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.86768375766015,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          41.5792,\n          57.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"B36\",\n          \"F4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "y_test = test_survived[['Survived']]\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(x_test.shape , y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JjeRm3nWYdT",
        "outputId": "c02f1e26-09a7-415d-caa5-8ce637f2f029"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(418, 7) (418, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(12).batch(16)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(12).batch(16)"
      ],
      "metadata": {
        "id": "Wg0YtVibjkqe"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model_titanic(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.d1 = Dense(16, activation='relu')\n",
        "    self.d2 = Dense(128, activation='relu')\n",
        "    self.d3 = Dense(2, activation='softmax')\n",
        "\n",
        "  def call(self,x):\n",
        "    x=self.d1(x)\n",
        "    x=self.d2(x)\n",
        "    x=self.d3(x)\n",
        "    return x\n",
        "\n",
        "model = model_titanic()\n"
      ],
      "metadata": {
        "id": "G5y3eIzSpPbQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "metadata": {
        "id": "h6qqI-WE0mmq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "wHPGcaQy1h0t"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train(x_train, y_train):\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred = model(x_train)\n",
        "    loss= loss_function(y_train, pred)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(y_train, pred)"
      ],
      "metadata": {
        "id": "b9sJzecT2d6k"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test(x_test, y_test):\n",
        "  pred = model(x_test)\n",
        "  loss = loss_function(y_test, pred)\n",
        "  test_loss(loss)\n",
        "  test_accuracy(y_test, pred)"
      ],
      "metadata": {
        "id": "ZHNUC6gVEiuO"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 35\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  # train\n",
        "  for x_train, y_train in train_dataset:\n",
        "    train(x_train, y_train)\n",
        "\n",
        "  # test\n",
        "  for x_test, y_test in test_dataset:\n",
        "    test(x_test, y_test)\n",
        "\n",
        "\n",
        "    print(\"epoch: \", epoch+1,\n",
        "          f\"train_loss: ,{train_loss.result()}\",\n",
        "          f\"train_accuracy: ,{train_accuracy.result()}\",\n",
        "          f\"test_loss: ,{test_loss.result()}\",\n",
        "          f\"test_accuracy: ,{test_accuracy.result()}\"\n",
        "\n",
        "          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39r58ji0TOdT",
        "outputId": "26fe8435-dbe3-4e52-fdec-c3d99b3f1495"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.6280055046081543 test_accuracy: ,0.75\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7751830816268921 test_accuracy: ,0.59375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.726243793964386 test_accuracy: ,0.5625\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.6866958141326904 test_accuracy: ,0.609375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7683825492858887 test_accuracy: ,0.5874999761581421\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7702897191047668 test_accuracy: ,0.5729166865348816\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7540324926376343 test_accuracy: ,0.5892857313156128\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7165689468383789 test_accuracy: ,0.609375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7198358178138733 test_accuracy: ,0.6111111044883728\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.715118944644928 test_accuracy: ,0.6000000238418579\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7198057770729065 test_accuracy: ,0.6022727489471436\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7095902562141418 test_accuracy: ,0.5989583134651184\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7229310274124146 test_accuracy: ,0.5961538553237915\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7233285307884216 test_accuracy: ,0.59375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7452443838119507 test_accuracy: ,0.5874999761581421\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7340955138206482 test_accuracy: ,0.59375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7265493273735046 test_accuracy: ,0.5992646813392639\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7202712893486023 test_accuracy: ,0.6041666865348816\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7190828919410706 test_accuracy: ,0.6118420958518982\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7243468165397644 test_accuracy: ,0.609375\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7302041053771973 test_accuracy: ,0.6101190447807312\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.734666109085083 test_accuracy: ,0.6051136255264282\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7213407754898071 test_accuracy: ,0.616847813129425\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7135246396064758 test_accuracy: ,0.6223958134651184\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7041908502578735 test_accuracy: ,0.6274999976158142\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.7077375650405884 test_accuracy: ,0.625\n",
            "epoch:  1 train_loss: ,0.6730896830558777 train_accuracy: ,0.6711559891700745 test_loss: ,0.6923012137413025 test_accuracy: ,0.6267942786216736\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.8131871223449707 test_accuracy: ,0.6875\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7596416473388672 test_accuracy: ,0.625\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7182057499885559 test_accuracy: ,0.625\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6998381614685059 test_accuracy: ,0.640625\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7869471311569214 test_accuracy: ,0.6000000238418579\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7629281878471375 test_accuracy: ,0.6145833134651184\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7434784770011902 test_accuracy: ,0.6160714030265808\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7106274366378784 test_accuracy: ,0.6484375\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7109559178352356 test_accuracy: ,0.6527777910232544\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7008811831474304 test_accuracy: ,0.6499999761581421\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6910669803619385 test_accuracy: ,0.6590909361839294\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7077112793922424 test_accuracy: ,0.65625\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7155044078826904 test_accuracy: ,0.6442307829856873\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7311615347862244 test_accuracy: ,0.6339285969734192\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.735553503036499 test_accuracy: ,0.6291666626930237\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7334598302841187 test_accuracy: ,0.625\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7235876321792603 test_accuracy: ,0.6323529481887817\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7174681425094604 test_accuracy: ,0.6319444179534912\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7123596668243408 test_accuracy: ,0.6348684430122375\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7207947373390198 test_accuracy: ,0.6312500238418579\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.708415687084198 test_accuracy: ,0.636904776096344\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7144997119903564 test_accuracy: ,0.6306818127632141\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.7034791111946106 test_accuracy: ,0.635869562625885\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6970677375793457 test_accuracy: ,0.6432291865348816\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6827856302261353 test_accuracy: ,0.6549999713897705\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6927015781402588 test_accuracy: ,0.6466346383094788\n",
            "epoch:  2 train_loss: ,0.6118900179862976 train_accuracy: ,0.6790123581886292 test_loss: ,0.6782519221305847 test_accuracy: ,0.6483253836631775\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,1.0133882761001587 test_accuracy: ,0.4375\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8113566637039185 test_accuracy: ,0.59375\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8239471316337585 test_accuracy: ,0.5625\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.7591029405593872 test_accuracy: ,0.59375\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.824728786945343 test_accuracy: ,0.574999988079071\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.9029286503791809 test_accuracy: ,0.5625\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8533920645713806 test_accuracy: ,0.5803571343421936\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.7992624640464783 test_accuracy: ,0.6015625\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8026345372200012 test_accuracy: ,0.5902777910232544\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.7884969115257263 test_accuracy: ,0.5874999761581421\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8235520720481873 test_accuracy: ,0.5852272510528564\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8057016730308533 test_accuracy: ,0.59375\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8058395981788635 test_accuracy: ,0.5865384340286255\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8586043119430542 test_accuracy: ,0.5714285969734192\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8642054200172424 test_accuracy: ,0.5708333253860474\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.862240731716156 test_accuracy: ,0.58203125\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8536397218704224 test_accuracy: ,0.5845588445663452\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8411356210708618 test_accuracy: ,0.59375\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8457720875740051 test_accuracy: ,0.6019737124443054\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8361879587173462 test_accuracy: ,0.606249988079071\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8536513447761536 test_accuracy: ,0.5982142686843872\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8470443487167358 test_accuracy: ,0.6022727489471436\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8302457928657532 test_accuracy: ,0.6114130616188049\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8291404843330383 test_accuracy: ,0.6145833134651184\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8151653409004211 test_accuracy: ,0.6200000047683716\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.8135110139846802 test_accuracy: ,0.6225961446762085\n",
            "epoch:  3 train_loss: ,0.6120414733886719 train_accuracy: ,0.6767676472663879 test_loss: ,0.815498411655426 test_accuracy: ,0.6220095753669739\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.8670253753662109 test_accuracy: ,0.5625\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7604034543037415 test_accuracy: ,0.59375\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.6537002921104431 test_accuracy: ,0.6458333134651184\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.6926383972167969 test_accuracy: ,0.59375\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.8416212201118469 test_accuracy: ,0.5625\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7969457507133484 test_accuracy: ,0.5729166865348816\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7565830945968628 test_accuracy: ,0.5892857313156128\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7399663329124451 test_accuracy: ,0.6015625\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7418301105499268 test_accuracy: ,0.6041666865348816\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7304705381393433 test_accuracy: ,0.606249988079071\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7219086289405823 test_accuracy: ,0.6136363744735718\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7185375094413757 test_accuracy: ,0.609375\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7490633726119995 test_accuracy: ,0.5961538553237915\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7495725750923157 test_accuracy: ,0.5892857313156128\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7502988576889038 test_accuracy: ,0.6000000238418579\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7693175673484802 test_accuracy: ,0.5859375\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.750412106513977 test_accuracy: ,0.5992646813392639\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7451552748680115 test_accuracy: ,0.6076388955116272\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7544149160385132 test_accuracy: ,0.6019737124443054\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7635876536369324 test_accuracy: ,0.6031249761581421\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7582783102989197 test_accuracy: ,0.6101190447807312\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7515416741371155 test_accuracy: ,0.6136363744735718\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7405579686164856 test_accuracy: ,0.6222826242446899\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7339310050010681 test_accuracy: ,0.6276041865348816\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7203044891357422 test_accuracy: ,0.6349999904632568\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7251359224319458 test_accuracy: ,0.6346153616905212\n",
            "epoch:  4 train_loss: ,0.6348846554756165 train_accuracy: ,0.6756453514099121 test_loss: ,0.7316510677337646 test_accuracy: ,0.6339712738990784\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7557231187820435 test_accuracy: ,0.625\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.774474561214447 test_accuracy: ,0.5625\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.6835400462150574 test_accuracy: ,0.6041666865348816\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7972756624221802 test_accuracy: ,0.578125\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.8238807916641235 test_accuracy: ,0.574999988079071\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.8324666619300842 test_accuracy: ,0.5625\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7936772108078003 test_accuracy: ,0.5714285969734192\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7495219707489014 test_accuracy: ,0.609375\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7273802161216736 test_accuracy: ,0.6111111044883728\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7675820589065552 test_accuracy: ,0.581250011920929\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.74837726354599 test_accuracy: ,0.5965909361839294\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7698681950569153 test_accuracy: ,0.59375\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7755807042121887 test_accuracy: ,0.5865384340286255\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7952789664268494 test_accuracy: ,0.5714285969734192\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7908064126968384 test_accuracy: ,0.5833333134651184\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.784821093082428 test_accuracy: ,0.59375\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7661086320877075 test_accuracy: ,0.5992646813392639\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7629258036613464 test_accuracy: ,0.6041666865348816\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7860464453697205 test_accuracy: ,0.5953947305679321\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7757695913314819 test_accuracy: ,0.6031249761581421\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.781558096408844 test_accuracy: ,0.6041666865348816\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7820857763290405 test_accuracy: ,0.6051136255264282\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7667692303657532 test_accuracy: ,0.614130437374115\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7587964534759521 test_accuracy: ,0.6223958134651184\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7518987059593201 test_accuracy: ,0.625\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.7499956488609314 test_accuracy: ,0.629807710647583\n",
            "epoch:  5 train_loss: ,0.6319907903671265 train_accuracy: ,0.6644219756126404 test_loss: ,0.756345808506012 test_accuracy: ,0.6291866302490234\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.8336324095726013 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.7200886011123657 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6384865641593933 test_accuracy: ,0.6458333134651184\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6803520917892456 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6680848002433777 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6991176009178162 test_accuracy: ,0.6145833134651184\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6698910593986511 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6328678131103516 test_accuracy: ,0.65625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6548002362251282 test_accuracy: ,0.6319444179534912\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6426316499710083 test_accuracy: ,0.6312500238418579\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6442551016807556 test_accuracy: ,0.6363636255264282\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6332630515098572 test_accuracy: ,0.65625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6432917714118958 test_accuracy: ,0.6538461446762085\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6553096175193787 test_accuracy: ,0.6383928656578064\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6613969206809998 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6570737957954407 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.645679235458374 test_accuracy: ,0.6323529481887817\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6533443927764893 test_accuracy: ,0.6215277910232544\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6490554213523865 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6532262563705444 test_accuracy: ,0.625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6463185548782349 test_accuracy: ,0.6279761791229248\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6421616673469543 test_accuracy: ,0.6278409361839294\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6388205289840698 test_accuracy: ,0.633152186870575\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6312456727027893 test_accuracy: ,0.640625\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6278974413871765 test_accuracy: ,0.6424999833106995\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.6257978677749634 test_accuracy: ,0.6466346383094788\n",
            "epoch:  6 train_loss: ,0.6569782495498657 train_accuracy: ,0.6666666865348816 test_loss: ,0.614315390586853 test_accuracy: ,0.6483253836631775\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.44167113304138184 test_accuracy: ,0.8125\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6783869862556458 test_accuracy: ,0.59375\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6508674621582031 test_accuracy: ,0.625\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6166399717330933 test_accuracy: ,0.671875\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.7072402238845825 test_accuracy: ,0.637499988079071\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6983992457389832 test_accuracy: ,0.6145833134651184\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6734580993652344 test_accuracy: ,0.6160714030265808\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6408496499061584 test_accuracy: ,0.640625\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6510715484619141 test_accuracy: ,0.6388888955116272\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6345516443252563 test_accuracy: ,0.643750011920929\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.637984037399292 test_accuracy: ,0.6477272510528564\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6283313632011414 test_accuracy: ,0.65625\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6512003540992737 test_accuracy: ,0.6490384340286255\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6529847383499146 test_accuracy: ,0.6383928656578064\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6654152274131775 test_accuracy: ,0.6291666626930237\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.659727156162262 test_accuracy: ,0.6328125\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6527642011642456 test_accuracy: ,0.6397058963775635\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6488692760467529 test_accuracy: ,0.6423611044883728\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6464632153511047 test_accuracy: ,0.6414473652839661\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6448322534561157 test_accuracy: ,0.643750011920929\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.642086386680603 test_accuracy: ,0.6458333134651184\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6512048244476318 test_accuracy: ,0.6363636255264282\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6382927894592285 test_accuracy: ,0.64673912525177\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6332486867904663 test_accuracy: ,0.6484375\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6215702295303345 test_accuracy: ,0.6625000238418579\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6263812184333801 test_accuracy: ,0.661057710647583\n",
            "epoch:  7 train_loss: ,0.6283416748046875 train_accuracy: ,0.6588103175163269 test_loss: ,0.6217182278633118 test_accuracy: ,0.660287082195282\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6800663471221924 test_accuracy: ,0.625\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.7408415675163269 test_accuracy: ,0.53125\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6639756560325623 test_accuracy: ,0.5833333134651184\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6390782594680786 test_accuracy: ,0.625\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.7245502471923828 test_accuracy: ,0.5874999761581421\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6888366341590881 test_accuracy: ,0.59375\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6436209678649902 test_accuracy: ,0.625\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6192486882209778 test_accuracy: ,0.6484375\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6134130358695984 test_accuracy: ,0.6458333134651184\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6351175308227539 test_accuracy: ,0.6312500238418579\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6222297549247742 test_accuracy: ,0.6420454382896423\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6142054200172424 test_accuracy: ,0.65625\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6303739547729492 test_accuracy: ,0.6538461446762085\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6407695412635803 test_accuracy: ,0.6517857313156128\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6387521624565125 test_accuracy: ,0.6499999761581421\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6337453126907349 test_accuracy: ,0.6484375\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6302347779273987 test_accuracy: ,0.6470588445663452\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6273635625839233 test_accuracy: ,0.6458333134651184\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6300208568572998 test_accuracy: ,0.6480262875556946\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6367768049240112 test_accuracy: ,0.643750011920929\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6332517266273499 test_accuracy: ,0.6428571343421936\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6302547454833984 test_accuracy: ,0.6420454382896423\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6241010427474976 test_accuracy: ,0.6494565010070801\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6170545220375061 test_accuracy: ,0.6536458134651184\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6150698661804199 test_accuracy: ,0.6600000262260437\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6080958843231201 test_accuracy: ,0.6634615659713745\n",
            "epoch:  8 train_loss: ,0.5982574224472046 train_accuracy: ,0.6734007000923157 test_loss: ,0.6229784488677979 test_accuracy: ,0.6626794338226318\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.7733370065689087 test_accuracy: ,0.625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.7099840641021729 test_accuracy: ,0.59375\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6594593524932861 test_accuracy: ,0.6041666865348816\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6125317811965942 test_accuracy: ,0.640625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6662527322769165 test_accuracy: ,0.6000000238418579\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6596322655677795 test_accuracy: ,0.6145833134651184\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6312829256057739 test_accuracy: ,0.625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6074421405792236 test_accuracy: ,0.65625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6154077053070068 test_accuracy: ,0.6597222089767456\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6177586913108826 test_accuracy: ,0.643750011920929\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6017497181892395 test_accuracy: ,0.6590909361839294\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5891452431678772 test_accuracy: ,0.6822916865348816\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6103363633155823 test_accuracy: ,0.6730769276618958\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6262712478637695 test_accuracy: ,0.65625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6238813400268555 test_accuracy: ,0.6541666388511658\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6154546141624451 test_accuracy: ,0.66015625\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6102397441864014 test_accuracy: ,0.6617646813392639\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6019169688224792 test_accuracy: ,0.6631944179534912\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6026247143745422 test_accuracy: ,0.6578947305679321\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6119896173477173 test_accuracy: ,0.653124988079071\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6074541807174683 test_accuracy: ,0.6577380895614624\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5989344120025635 test_accuracy: ,0.6647727489471436\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.6007270812988281 test_accuracy: ,0.6603260636329651\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5898650288581848 test_accuracy: ,0.6692708134651184\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5840433239936829 test_accuracy: ,0.675000011920929\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5874108076095581 test_accuracy: ,0.6730769276618958\n",
            "epoch:  9 train_loss: ,0.622810423374176 train_accuracy: ,0.6677889823913574 test_loss: ,0.5762719511985779 test_accuracy: ,0.6746411323547363\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.7860919237136841 test_accuracy: ,0.625\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6414625644683838 test_accuracy: ,0.65625\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.62113356590271 test_accuracy: ,0.6458333134651184\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6110858917236328 test_accuracy: ,0.65625\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6647619605064392 test_accuracy: ,0.637499988079071\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6379225850105286 test_accuracy: ,0.6354166865348816\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6248031854629517 test_accuracy: ,0.6339285969734192\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5896793603897095 test_accuracy: ,0.6640625\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5896103382110596 test_accuracy: ,0.6597222089767456\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5768736600875854 test_accuracy: ,0.668749988079071\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5784285068511963 test_accuracy: ,0.6761363744735718\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6008031964302063 test_accuracy: ,0.6666666865348816\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6133412718772888 test_accuracy: ,0.6682692170143127\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6111711859703064 test_accuracy: ,0.6607142686843872\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6177446842193604 test_accuracy: ,0.6541666388511658\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.6132444739341736 test_accuracy: ,0.65625\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5936564207077026 test_accuracy: ,0.6691176295280457\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5860271453857422 test_accuracy: ,0.6736111044883728\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5876983404159546 test_accuracy: ,0.6743420958518982\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5971636772155762 test_accuracy: ,0.6656249761581421\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.59139484167099 test_accuracy: ,0.6726190447807312\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5910015106201172 test_accuracy: ,0.6704545617103577\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5855980515480042 test_accuracy: ,0.6739130616188049\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5793647170066833 test_accuracy: ,0.6796875\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.575432300567627 test_accuracy: ,0.6825000047683716\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5719730854034424 test_accuracy: ,0.682692289352417\n",
            "epoch:  10 train_loss: ,0.5939803719520569 train_accuracy: ,0.680134654045105 test_loss: ,0.5999495983123779 test_accuracy: ,0.6818181872367859\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.6970893740653992 test_accuracy: ,0.625\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.6560958623886108 test_accuracy: ,0.65625\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.6232962012290955 test_accuracy: ,0.6666666865348816\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.616390585899353 test_accuracy: ,0.640625\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.6137278079986572 test_accuracy: ,0.6499999761581421\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.6271982789039612 test_accuracy: ,0.6458333134651184\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5953675508499146 test_accuracy: ,0.6607142686843872\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5814267992973328 test_accuracy: ,0.671875\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5772612690925598 test_accuracy: ,0.6875\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5793001651763916 test_accuracy: ,0.675000011920929\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5657094717025757 test_accuracy: ,0.6931818127632141\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5511930584907532 test_accuracy: ,0.7135416865348816\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5704444646835327 test_accuracy: ,0.7067307829856873\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5878264307975769 test_accuracy: ,0.6919642686843872\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5885318517684937 test_accuracy: ,0.6833333373069763\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.586184024810791 test_accuracy: ,0.68359375\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5788797736167908 test_accuracy: ,0.6875\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5744778513908386 test_accuracy: ,0.6909722089767456\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5715051293373108 test_accuracy: ,0.6907894611358643\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5757822394371033 test_accuracy: ,0.690625011920929\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5683547854423523 test_accuracy: ,0.6964285969734192\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5671741962432861 test_accuracy: ,0.6960227489471436\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5646243095397949 test_accuracy: ,0.7010869383811951\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5617276430130005 test_accuracy: ,0.7005208134651184\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5618428587913513 test_accuracy: ,0.7024999856948853\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5578064322471619 test_accuracy: ,0.7091346383094788\n",
            "epoch:  11 train_loss: ,0.579809844493866 train_accuracy: ,0.6924803853034973 test_loss: ,0.5501093864440918 test_accuracy: ,0.7105262875556946\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.47471606731414795 test_accuracy: ,0.8125\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5854378938674927 test_accuracy: ,0.71875\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.570999026298523 test_accuracy: ,0.6666666865348816\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5822895169258118 test_accuracy: ,0.671875\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5879052877426147 test_accuracy: ,0.6499999761581421\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.6158422827720642 test_accuracy: ,0.6458333134651184\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5874170064926147 test_accuracy: ,0.6607142686843872\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5534213781356812 test_accuracy: ,0.6953125\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5468807220458984 test_accuracy: ,0.6944444179534912\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5462872982025146 test_accuracy: ,0.6937500238418579\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5420939922332764 test_accuracy: ,0.6931818127632141\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5576031804084778 test_accuracy: ,0.703125\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.566261887550354 test_accuracy: ,0.6971153616905212\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5725676417350769 test_accuracy: ,0.6919642686843872\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5741757154464722 test_accuracy: ,0.6833333373069763\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5752044916152954 test_accuracy: ,0.6796875\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5674433708190918 test_accuracy: ,0.6875\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5630141496658325 test_accuracy: ,0.6909722089767456\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5618764162063599 test_accuracy: ,0.6907894611358643\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5573448538780212 test_accuracy: ,0.6937500238418579\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.549513578414917 test_accuracy: ,0.7053571343421936\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.555385410785675 test_accuracy: ,0.6988636255264282\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5475153923034668 test_accuracy: ,0.7038043737411499\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5464213490486145 test_accuracy: ,0.703125\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5428474545478821 test_accuracy: ,0.7074999809265137\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.5416196584701538 test_accuracy: ,0.7115384340286255\n",
            "epoch:  12 train_loss: ,0.5712696313858032 train_accuracy: ,0.7081930637359619 test_loss: ,0.535250723361969 test_accuracy: ,0.7129186391830444\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5594949722290039 test_accuracy: ,0.8125\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5800122022628784 test_accuracy: ,0.6875\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5806180834770203 test_accuracy: ,0.6875\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5531481504440308 test_accuracy: ,0.6875\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5884438157081604 test_accuracy: ,0.6499999761581421\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.589049756526947 test_accuracy: ,0.6458333134651184\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.568394124507904 test_accuracy: ,0.6607142686843872\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5378813147544861 test_accuracy: ,0.6796875\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.532951295375824 test_accuracy: ,0.7013888955116272\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5403546690940857 test_accuracy: ,0.6937500238418579\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.530038058757782 test_accuracy: ,0.7045454382896423\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5425007343292236 test_accuracy: ,0.7083333134651184\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5568060278892517 test_accuracy: ,0.7019230723381042\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5579252243041992 test_accuracy: ,0.6964285969734192\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5574122071266174 test_accuracy: ,0.6958333253860474\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5492845773696899 test_accuracy: ,0.6953125\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5466285347938538 test_accuracy: ,0.6985294222831726\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5415096282958984 test_accuracy: ,0.6979166865348816\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5338117480278015 test_accuracy: ,0.7072368264198303\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5358098149299622 test_accuracy: ,0.703125\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5333956480026245 test_accuracy: ,0.7023809552192688\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5346599817276001 test_accuracy: ,0.7017045617103577\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5330480337142944 test_accuracy: ,0.7038043737411499\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5333266854286194 test_accuracy: ,0.703125\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5303112268447876 test_accuracy: ,0.7099999785423279\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5253438949584961 test_accuracy: ,0.7163461446762085\n",
            "epoch:  13 train_loss: ,0.5853432416915894 train_accuracy: ,0.7003366947174072 test_loss: ,0.5146133899688721 test_accuracy: ,0.7177033424377441\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.43210533261299133 test_accuracy: ,0.8125\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.6050994992256165 test_accuracy: ,0.65625\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5198020339012146 test_accuracy: ,0.75\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5524137020111084 test_accuracy: ,0.6875\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5976856350898743 test_accuracy: ,0.6625000238418579\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5719195008277893 test_accuracy: ,0.6666666865348816\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5505289435386658 test_accuracy: ,0.6785714030265808\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5448452830314636 test_accuracy: ,0.6796875\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5479887127876282 test_accuracy: ,0.6944444179534912\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5288345813751221 test_accuracy: ,0.706250011920929\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5268979072570801 test_accuracy: ,0.7102272510528564\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5370792746543884 test_accuracy: ,0.7135416865348816\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5524832606315613 test_accuracy: ,0.7067307829856873\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5490971207618713 test_accuracy: ,0.7053571343421936\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5569937825202942 test_accuracy: ,0.699999988079071\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5552875399589539 test_accuracy: ,0.69921875\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5429581999778748 test_accuracy: ,0.7095588445663452\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5393487811088562 test_accuracy: ,0.7118055820465088\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5335353016853333 test_accuracy: ,0.7171052694320679\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5396299958229065 test_accuracy: ,0.7124999761581421\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5330147743225098 test_accuracy: ,0.7172619104385376\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5307843685150146 test_accuracy: ,0.7159090638160706\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5283164978027344 test_accuracy: ,0.717391312122345\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5272402167320251 test_accuracy: ,0.71875\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.524737536907196 test_accuracy: ,0.7225000262260437\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5197393894195557 test_accuracy: ,0.7283653616905212\n",
            "epoch:  14 train_loss: ,0.5506789088249207 train_accuracy: ,0.7138047218322754 test_loss: ,0.5125451683998108 test_accuracy: ,0.7296651005744934\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5808010101318359 test_accuracy: ,0.6875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5384836792945862 test_accuracy: ,0.71875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5448601841926575 test_accuracy: ,0.6875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5264602899551392 test_accuracy: ,0.6875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5662807822227478 test_accuracy: ,0.6625000238418579\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5647138357162476 test_accuracy: ,0.6458333134651184\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5328091979026794 test_accuracy: ,0.6696428656578064\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5143222808837891 test_accuracy: ,0.6875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5290867686271667 test_accuracy: ,0.6944444179534912\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5160491466522217 test_accuracy: ,0.699999988079071\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5132915377616882 test_accuracy: ,0.7045454382896423\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.523899257183075 test_accuracy: ,0.7135416865348816\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5313034057617188 test_accuracy: ,0.7067307829856873\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5354582071304321 test_accuracy: ,0.7098214030265808\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5392277836799622 test_accuracy: ,0.6958333253860474\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5299378633499146 test_accuracy: ,0.70703125\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5220880508422852 test_accuracy: ,0.7132353186607361\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5184686779975891 test_accuracy: ,0.7152777910232544\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5220747590065002 test_accuracy: ,0.7072368264198303\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5237222909927368 test_accuracy: ,0.7093750238418579\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5167658925056458 test_accuracy: ,0.7202380895614624\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5148378014564514 test_accuracy: ,0.71875\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.514255166053772 test_accuracy: ,0.720108687877655\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5111815333366394 test_accuracy: ,0.7213541865348816\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5071089267730713 test_accuracy: ,0.7300000190734863\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.5047396421432495 test_accuracy: ,0.7307692170143127\n",
            "epoch:  15 train_loss: ,0.5593911409378052 train_accuracy: ,0.7171717286109924 test_loss: ,0.4922533631324768 test_accuracy: ,0.7320573925971985\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.6111609935760498 test_accuracy: ,0.6875\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.6086048483848572 test_accuracy: ,0.625\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5701051354408264 test_accuracy: ,0.6458333134651184\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.53179532289505 test_accuracy: ,0.671875\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5389374494552612 test_accuracy: ,0.6499999761581421\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5483735203742981 test_accuracy: ,0.65625\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5260735154151917 test_accuracy: ,0.6785714030265808\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5066882967948914 test_accuracy: ,0.6953125\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5034030079841614 test_accuracy: ,0.7083333134651184\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4994000792503357 test_accuracy: ,0.7124999761581421\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.48322343826293945 test_accuracy: ,0.7329545617103577\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5015920996665955 test_accuracy: ,0.7239583134651184\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5111124515533447 test_accuracy: ,0.7211538553237915\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5120105743408203 test_accuracy: ,0.71875\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5147514939308167 test_accuracy: ,0.7124999761581421\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.511549174785614 test_accuracy: ,0.71484375\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5020665526390076 test_accuracy: ,0.720588207244873\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.5053285956382751 test_accuracy: ,0.7118055820465088\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4991885721683502 test_accuracy: ,0.7171052694320679\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4994128346443176 test_accuracy: ,0.71875\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.49515342712402344 test_accuracy: ,0.7291666865348816\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.49295589327812195 test_accuracy: ,0.7272727489471436\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4956171214580536 test_accuracy: ,0.7255434989929199\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4903564453125 test_accuracy: ,0.7317708134651184\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.486897349357605 test_accuracy: ,0.7350000143051147\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.4874391555786133 test_accuracy: ,0.7355769276618958\n",
            "epoch:  16 train_loss: ,0.5309529900550842 train_accuracy: ,0.7306397557258606 test_loss: ,0.47491157054901123 test_accuracy: ,0.7368420958518982\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5027060508728027 test_accuracy: ,0.6875\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5246713161468506 test_accuracy: ,0.71875\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5101819038391113 test_accuracy: ,0.7083333134651184\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5125952959060669 test_accuracy: ,0.6875\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.48510247468948364 test_accuracy: ,0.7250000238418579\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5501811504364014 test_accuracy: ,0.6770833134651184\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5212059617042542 test_accuracy: ,0.7053571343421936\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4975263178348541 test_accuracy: ,0.7109375\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.48751100897789 test_accuracy: ,0.7291666865348816\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4845920205116272 test_accuracy: ,0.737500011920929\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4893803596496582 test_accuracy: ,0.7272727489471436\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5026400685310364 test_accuracy: ,0.7291666865348816\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5015692114830017 test_accuracy: ,0.7259615659713745\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5073713064193726 test_accuracy: ,0.7232142686843872\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.500703752040863 test_accuracy: ,0.7291666865348816\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5052859783172607 test_accuracy: ,0.72265625\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5023022294044495 test_accuracy: ,0.7242646813392639\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.49602290987968445 test_accuracy: ,0.7256944179534912\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.49931585788726807 test_accuracy: ,0.7236841917037964\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.5007938146591187 test_accuracy: ,0.7250000238418579\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4935043454170227 test_accuracy: ,0.738095223903656\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.489050030708313 test_accuracy: ,0.7357954382896423\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4858822524547577 test_accuracy: ,0.739130437374115\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.48085781931877136 test_accuracy: ,0.7447916865348816\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4783761203289032 test_accuracy: ,0.7450000047683716\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4743099808692932 test_accuracy: ,0.75\n",
            "epoch:  17 train_loss: ,0.5268902778625488 train_accuracy: ,0.7283950448036194 test_loss: ,0.4975316524505615 test_accuracy: ,0.7488038539886475\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.6192417740821838 test_accuracy: ,0.625\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.550437867641449 test_accuracy: ,0.65625\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.5194665789604187 test_accuracy: ,0.6875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.5147424936294556 test_accuracy: ,0.6875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.5122613906860352 test_accuracy: ,0.6875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.49158477783203125 test_accuracy: ,0.6979166865348816\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4804384410381317 test_accuracy: ,0.7142857313156128\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.45359116792678833 test_accuracy: ,0.7421875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.46359315514564514 test_accuracy: ,0.7361111044883728\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4493299126625061 test_accuracy: ,0.7437499761581421\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4507228136062622 test_accuracy: ,0.7443181872367859\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.46951648592948914 test_accuracy: ,0.7395833134651184\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.476906955242157 test_accuracy: ,0.7355769276618958\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4794332981109619 test_accuracy: ,0.7321428656578064\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.47972363233566284 test_accuracy: ,0.7291666865348816\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4736659526824951 test_accuracy: ,0.73046875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.46623554825782776 test_accuracy: ,0.7352941036224365\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.462027907371521 test_accuracy: ,0.7361111044883728\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.46136152744293213 test_accuracy: ,0.7335526347160339\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4618392586708069 test_accuracy: ,0.731249988079071\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4580106735229492 test_accuracy: ,0.7351190447807312\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4542686343193054 test_accuracy: ,0.7386363744735718\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4543786644935608 test_accuracy: ,0.739130437374115\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4511631727218628 test_accuracy: ,0.7421875\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.44823139905929565 test_accuracy: ,0.7475000023841858\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4471616744995117 test_accuracy: ,0.7475961446762085\n",
            "epoch:  18 train_loss: ,0.5240339636802673 train_accuracy: ,0.744107723236084 test_loss: ,0.4496705234050751 test_accuracy: ,0.7488038539886475\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4971788823604584 test_accuracy: ,0.6875\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.5063292980194092 test_accuracy: ,0.6875\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.46922269463539124 test_accuracy: ,0.7083333134651184\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4662482440471649 test_accuracy: ,0.71875\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4715617299079895 test_accuracy: ,0.7124999761581421\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4951116144657135 test_accuracy: ,0.6875\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4664492607116699 test_accuracy: ,0.7142857313156128\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4453621804714203 test_accuracy: ,0.7421875\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4356466233730316 test_accuracy: ,0.7569444179534912\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4407172203063965 test_accuracy: ,0.75\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4503447711467743 test_accuracy: ,0.7386363744735718\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.46021589636802673 test_accuracy: ,0.7447916865348816\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4663267731666565 test_accuracy: ,0.7355769276618958\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4594976007938385 test_accuracy: ,0.7455357313156128\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4639175832271576 test_accuracy: ,0.7333333492279053\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4601229727268219 test_accuracy: ,0.734375\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.45559588074684143 test_accuracy: ,0.7426470518112183\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.45309796929359436 test_accuracy: ,0.7395833134651184\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4516322910785675 test_accuracy: ,0.7401315569877625\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.45502644777297974 test_accuracy: ,0.7406250238418579\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4505906403064728 test_accuracy: ,0.7470238208770752\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4462265074253082 test_accuracy: ,0.7471590638160706\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.4495287239551544 test_accuracy: ,0.75\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.44676098227500916 test_accuracy: ,0.75\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.44118157029151917 test_accuracy: ,0.7549999952316284\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.43764370679855347 test_accuracy: ,0.7596153616905212\n",
            "epoch:  19 train_loss: ,0.5153294801712036 train_accuracy: ,0.7463524341583252 test_loss: ,0.445587694644928 test_accuracy: ,0.7583732008934021\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.46066951751708984 test_accuracy: ,0.6875\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4745369553565979 test_accuracy: ,0.6875\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4744435250759125 test_accuracy: ,0.7083333134651184\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4561237394809723 test_accuracy: ,0.734375\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.45120707154273987 test_accuracy: ,0.737500011920929\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.44930967688560486 test_accuracy: ,0.75\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4536626636981964 test_accuracy: ,0.75\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4290256202220917 test_accuracy: ,0.7734375\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4309695065021515 test_accuracy: ,0.7777777910232544\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.43764591217041016 test_accuracy: ,0.768750011920929\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.43759286403656006 test_accuracy: ,0.7613636255264282\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.43874505162239075 test_accuracy: ,0.7760416865348816\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4599601626396179 test_accuracy: ,0.75\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.45341113209724426 test_accuracy: ,0.7544642686843872\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4479774236679077 test_accuracy: ,0.7583333253860474\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.44732701778411865 test_accuracy: ,0.76171875\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.44218137860298157 test_accuracy: ,0.7647058963775635\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.43589338660240173 test_accuracy: ,0.7638888955116272\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4401169717311859 test_accuracy: ,0.7598684430122375\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4343906044960022 test_accuracy: ,0.765625\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4320763647556305 test_accuracy: ,0.7708333134651184\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4285711348056793 test_accuracy: ,0.7727272510528564\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.43171995878219604 test_accuracy: ,0.77173912525177\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.42866650223731995 test_accuracy: ,0.7734375\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4241713285446167 test_accuracy: ,0.7799999713897705\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.41949695348739624 test_accuracy: ,0.7836538553237915\n",
            "epoch:  20 train_loss: ,0.5071574449539185 train_accuracy: ,0.7508417367935181 test_loss: ,0.4363817274570465 test_accuracy: ,0.7822966575622559\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.31252139806747437 test_accuracy: ,0.875\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.427711546421051 test_accuracy: ,0.78125\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.43216338753700256 test_accuracy: ,0.7708333134651184\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.40939804911613464 test_accuracy: ,0.78125\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.44196271896362305 test_accuracy: ,0.762499988079071\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.44212403893470764 test_accuracy: ,0.7708333134651184\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.43009915947914124 test_accuracy: ,0.7857142686843872\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4318150579929352 test_accuracy: ,0.78125\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.42310816049575806 test_accuracy: ,0.7916666865348816\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4236854612827301 test_accuracy: ,0.7875000238418579\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.40732285380363464 test_accuracy: ,0.8011363744735718\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4316270351409912 test_accuracy: ,0.7916666865348816\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4508141875267029 test_accuracy: ,0.7692307829856873\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4491930603981018 test_accuracy: ,0.7678571343421936\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.44643351435661316 test_accuracy: ,0.7708333134651184\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4421508312225342 test_accuracy: ,0.7734375\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.43558448553085327 test_accuracy: ,0.7757353186607361\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.42965665459632874 test_accuracy: ,0.78125\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.42614510655403137 test_accuracy: ,0.7828947305679321\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4278056025505066 test_accuracy: ,0.78125\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4301374852657318 test_accuracy: ,0.7827380895614624\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.421729177236557 test_accuracy: ,0.7897727489471436\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.4216722846031189 test_accuracy: ,0.79347825050354\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.42242422699928284 test_accuracy: ,0.7916666865348816\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.41905489563941956 test_accuracy: ,0.7950000166893005\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.415593683719635 test_accuracy: ,0.7956730723381042\n",
            "epoch:  21 train_loss: ,0.505053699016571 train_accuracy: ,0.7631874084472656 test_loss: ,0.42127615213394165 test_accuracy: ,0.7942583560943604\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.589442253112793 test_accuracy: ,0.5625\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.45256519317626953 test_accuracy: ,0.6875\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4460083544254303 test_accuracy: ,0.7083333134651184\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.430636465549469 test_accuracy: ,0.734375\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4559164047241211 test_accuracy: ,0.737500011920929\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4405190646648407 test_accuracy: ,0.7395833134651184\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4325888156890869 test_accuracy: ,0.7589285969734192\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4179328978061676 test_accuracy: ,0.7734375\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4210754930973053 test_accuracy: ,0.7777777910232544\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4169023633003235 test_accuracy: ,0.78125\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4152098596096039 test_accuracy: ,0.7727272510528564\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.40337225794792175 test_accuracy: ,0.78125\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.43853092193603516 test_accuracy: ,0.7644230723381042\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4278590679168701 test_accuracy: ,0.7723214030265808\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.42859527468681335 test_accuracy: ,0.7708333134651184\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4241437017917633 test_accuracy: ,0.78125\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4175126552581787 test_accuracy: ,0.783088207244873\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.41637468338012695 test_accuracy: ,0.78125\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4166782796382904 test_accuracy: ,0.7828947305679321\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4152359068393707 test_accuracy: ,0.78125\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.4091349244117737 test_accuracy: ,0.7857142686843872\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.40929654240608215 test_accuracy: ,0.7897727489471436\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.402942955493927 test_accuracy: ,0.7961956262588501\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.40556034445762634 test_accuracy: ,0.7994791865348816\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.40151336789131165 test_accuracy: ,0.800000011920929\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.40204155445098877 test_accuracy: ,0.8028846383094788\n",
            "epoch:  22 train_loss: ,0.49561524391174316 train_accuracy: ,0.7620651125907898 test_loss: ,0.39924299716949463 test_accuracy: ,0.8038277626037598\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.40006348490715027 test_accuracy: ,0.75\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.3801405727863312 test_accuracy: ,0.78125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.41119444370269775 test_accuracy: ,0.75\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.420360803604126 test_accuracy: ,0.78125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4405739903450012 test_accuracy: ,0.7749999761581421\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4458325207233429 test_accuracy: ,0.7708333134651184\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.40227630734443665 test_accuracy: ,0.8035714030265808\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.3872634172439575 test_accuracy: ,0.8203125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.39923885464668274 test_accuracy: ,0.8125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.3987937271595001 test_accuracy: ,0.8125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4015633761882782 test_accuracy: ,0.7954545617103577\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.41130271553993225 test_accuracy: ,0.8020833134651184\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.41633135080337524 test_accuracy: ,0.7980769276618958\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4234667420387268 test_accuracy: ,0.7946428656578064\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4155661463737488 test_accuracy: ,0.8041666746139526\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4143071472644806 test_accuracy: ,0.8046875\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4078444540500641 test_accuracy: ,0.8088235259056091\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.40966594219207764 test_accuracy: ,0.8090277910232544\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4034327566623688 test_accuracy: ,0.8092105388641357\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.4033576548099518 test_accuracy: ,0.809374988079071\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.40076524019241333 test_accuracy: ,0.8125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.39713364839553833 test_accuracy: ,0.8125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.40247219800949097 test_accuracy: ,0.8125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.39585408568382263 test_accuracy: ,0.8203125\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.39488303661346436 test_accuracy: ,0.8199999928474426\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.3908691108226776 test_accuracy: ,0.8245192170143127\n",
            "epoch:  23 train_loss: ,0.4970197379589081 train_accuracy: ,0.7609427571296692 test_loss: ,0.38738879561424255 test_accuracy: ,0.8253588676452637\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3522997498512268 test_accuracy: ,0.8125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4047281742095947 test_accuracy: ,0.75\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.42499110102653503 test_accuracy: ,0.75\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4173716902732849 test_accuracy: ,0.78125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3979286551475525 test_accuracy: ,0.8125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4258534014225006 test_accuracy: ,0.8020833134651184\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4008145332336426 test_accuracy: ,0.8214285969734192\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3896918296813965 test_accuracy: ,0.8203125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3957737684249878 test_accuracy: ,0.8194444179534912\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.38797539472579956 test_accuracy: ,0.824999988079071\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3866250216960907 test_accuracy: ,0.8125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3891817629337311 test_accuracy: ,0.8072916865348816\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4176986813545227 test_accuracy: ,0.7980769276618958\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.41243061423301697 test_accuracy: ,0.8080357313156128\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.4122326672077179 test_accuracy: ,0.8083333373069763\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.40735459327697754 test_accuracy: ,0.80859375\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.40258756279945374 test_accuracy: ,0.8088235259056091\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.39369168877601624 test_accuracy: ,0.8194444179534912\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.39785027503967285 test_accuracy: ,0.8190789222717285\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.39544740319252014 test_accuracy: ,0.8187500238418579\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.39023488759994507 test_accuracy: ,0.824404776096344\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3880442678928375 test_accuracy: ,0.8267045617103577\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.381204217672348 test_accuracy: ,0.83152174949646\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3872183859348297 test_accuracy: ,0.828125\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3797004818916321 test_accuracy: ,0.8349999785423279\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.38108131289482117 test_accuracy: ,0.8365384340286255\n",
            "epoch:  24 train_loss: ,0.49846771359443665 train_accuracy: ,0.7643097639083862 test_loss: ,0.3883337676525116 test_accuracy: ,0.8349282145500183\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.31252938508987427 test_accuracy: ,0.875\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.40285444259643555 test_accuracy: ,0.75\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.39965593814849854 test_accuracy: ,0.7708333134651184\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.39113283157348633 test_accuracy: ,0.796875\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.4014098644256592 test_accuracy: ,0.8125\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3974854648113251 test_accuracy: ,0.8125\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.37610504031181335 test_accuracy: ,0.8214285969734192\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.37302640080451965 test_accuracy: ,0.8203125\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.37147095799446106 test_accuracy: ,0.8263888955116272\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3668283522129059 test_accuracy: ,0.824999988079071\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.36584147810935974 test_accuracy: ,0.8181818127632141\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.38789090514183044 test_accuracy: ,0.8177083134651184\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.39811670780181885 test_accuracy: ,0.807692289352417\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3927929103374481 test_accuracy: ,0.8125\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3909418284893036 test_accuracy: ,0.8208333253860474\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.38559311628341675 test_accuracy: ,0.82421875\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3886573016643524 test_accuracy: ,0.8161764740943909\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.38113027811050415 test_accuracy: ,0.8263888955116272\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3772868812084198 test_accuracy: ,0.8289473652839661\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.37525585293769836 test_accuracy: ,0.8343750238418579\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.37482017278671265 test_accuracy: ,0.836309552192688\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3705318570137024 test_accuracy: ,0.8409090638160706\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3700561225414276 test_accuracy: ,0.8396739363670349\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.36948657035827637 test_accuracy: ,0.84375\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.36515867710113525 test_accuracy: ,0.8500000238418579\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.3681696653366089 test_accuracy: ,0.8461538553237915\n",
            "epoch:  25 train_loss: ,0.47743722796440125 train_accuracy: ,0.7744107842445374 test_loss: ,0.36380326747894287 test_accuracy: ,0.8468899726867676\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.29249924421310425 test_accuracy: ,0.875\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3950706124305725 test_accuracy: ,0.75\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.38551220297813416 test_accuracy: ,0.7916666865348816\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36947259306907654 test_accuracy: ,0.8125\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.39413946866989136 test_accuracy: ,0.8125\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.39744141697883606 test_accuracy: ,0.8020833134651184\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.37233299016952515 test_accuracy: ,0.8214285969734192\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.364376962184906 test_accuracy: ,0.828125\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36204084753990173 test_accuracy: ,0.8263888955116272\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.35219964385032654 test_accuracy: ,0.831250011920929\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3560105562210083 test_accuracy: ,0.8238636255264282\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.38399815559387207 test_accuracy: ,0.8177083134651184\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.39509934186935425 test_accuracy: ,0.8125\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3900182545185089 test_accuracy: ,0.8214285969734192\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.38848134875297546 test_accuracy: ,0.8208333253860474\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3825933337211609 test_accuracy: ,0.82421875\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3747333586215973 test_accuracy: ,0.8308823704719543\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3737057149410248 test_accuracy: ,0.8333333134651184\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3702361583709717 test_accuracy: ,0.8388158082962036\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3753085732460022 test_accuracy: ,0.8343750238418579\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36717885732650757 test_accuracy: ,0.8422619104385376\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36563846468925476 test_accuracy: ,0.84375\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36181557178497314 test_accuracy: ,0.845108687877655\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3695574700832367 test_accuracy: ,0.84375\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.3637000322341919 test_accuracy: ,0.8500000238418579\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.36334672570228577 test_accuracy: ,0.8509615659713745\n",
            "epoch:  26 train_loss: ,0.472920686006546 train_accuracy: ,0.7721661329269409 test_loss: ,0.35341212153434753 test_accuracy: ,0.8516746163368225\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3409363031387329 test_accuracy: ,0.8125\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.4064542353153229 test_accuracy: ,0.8125\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3807639181613922 test_accuracy: ,0.7916666865348816\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.35707178711891174 test_accuracy: ,0.8125\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3856097161769867 test_accuracy: ,0.800000011920929\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.409930944442749 test_accuracy: ,0.8020833134651184\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3831733167171478 test_accuracy: ,0.8303571343421936\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3705776035785675 test_accuracy: ,0.84375\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3950918912887573 test_accuracy: ,0.8194444179534912\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3791881799697876 test_accuracy: ,0.831250011920929\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3739476501941681 test_accuracy: ,0.8352272510528564\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.39440229535102844 test_accuracy: ,0.8333333134651184\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.4039653539657593 test_accuracy: ,0.8269230723381042\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.40365079045295715 test_accuracy: ,0.8258928656578064\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.40321046113967896 test_accuracy: ,0.8291666507720947\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3967209756374359 test_accuracy: ,0.83203125\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.39134156703948975 test_accuracy: ,0.8345588445663452\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3871663510799408 test_accuracy: ,0.8368055820465088\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3894500434398651 test_accuracy: ,0.8289473652839661\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3850122094154358 test_accuracy: ,0.828125\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3861995339393616 test_accuracy: ,0.8303571343421936\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.381864458322525 test_accuracy: ,0.8352272510528564\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3846319317817688 test_accuracy: ,0.83423912525177\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3799280822277069 test_accuracy: ,0.8359375\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3735629916191101 test_accuracy: ,0.8424999713897705\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.3775480091571808 test_accuracy: ,0.838942289352417\n",
            "epoch:  27 train_loss: ,0.47075051069259644 train_accuracy: ,0.7800224423408508 test_loss: ,0.36548084020614624 test_accuracy: ,0.839712917804718\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.4909941554069519 test_accuracy: ,0.75\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.38793492317199707 test_accuracy: ,0.8125\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3796401917934418 test_accuracy: ,0.8125\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3751501441001892 test_accuracy: ,0.859375\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.38505658507347107 test_accuracy: ,0.8500000238418579\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3845570981502533 test_accuracy: ,0.8541666865348816\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3612980842590332 test_accuracy: ,0.8660714030265808\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.35282278060913086 test_accuracy: ,0.8671875\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3554936349391937 test_accuracy: ,0.8611111044883728\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.35226011276245117 test_accuracy: ,0.856249988079071\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3448781669139862 test_accuracy: ,0.8636363744735718\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3428153097629547 test_accuracy: ,0.8645833134651184\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3726312518119812 test_accuracy: ,0.8605769276618958\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3714981973171234 test_accuracy: ,0.8616071343421936\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.37454959750175476 test_accuracy: ,0.8666666746139526\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.36562371253967285 test_accuracy: ,0.87109375\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.36628609895706177 test_accuracy: ,0.8602941036224365\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3578804135322571 test_accuracy: ,0.8680555820465088\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.35586458444595337 test_accuracy: ,0.8717105388641357\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.35384851694107056 test_accuracy: ,0.871874988079071\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3509034216403961 test_accuracy: ,0.875\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3497988283634186 test_accuracy: ,0.8721590638160706\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3540342152118683 test_accuracy: ,0.8722826242446899\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.35349908471107483 test_accuracy: ,0.8723958134651184\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.3518429100513458 test_accuracy: ,0.875\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.34943389892578125 test_accuracy: ,0.8774038553237915\n",
            "epoch:  28 train_loss: ,0.4844348728656769 train_accuracy: ,0.7721661329269409 test_loss: ,0.33895912766456604 test_accuracy: ,0.8779904246330261\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.44569841027259827 test_accuracy: ,0.75\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.38225728273391724 test_accuracy: ,0.84375\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.35801902413368225 test_accuracy: ,0.8333333134651184\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.34934288263320923 test_accuracy: ,0.859375\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.38768142461776733 test_accuracy: ,0.8500000238418579\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.37284597754478455 test_accuracy: ,0.8541666865348816\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3500280976295471 test_accuracy: ,0.8660714030265808\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3438430428504944 test_accuracy: ,0.875\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3418349027633667 test_accuracy: ,0.8680555820465088\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.34038084745407104 test_accuracy: ,0.862500011920929\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.33332690596580505 test_accuracy: ,0.8693181872367859\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3611714541912079 test_accuracy: ,0.859375\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.36877569556236267 test_accuracy: ,0.8557692170143127\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.36178058385849 test_accuracy: ,0.8616071343421936\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3641164004802704 test_accuracy: ,0.862500011920929\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.35899075865745544 test_accuracy: ,0.87109375\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3558010160923004 test_accuracy: ,0.8639705777168274\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3522929847240448 test_accuracy: ,0.8680555820465088\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.34906065464019775 test_accuracy: ,0.875\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3492157459259033 test_accuracy: ,0.871874988079071\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.34717392921447754 test_accuracy: ,0.875\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.33949947357177734 test_accuracy: ,0.8806818127632141\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.34591659903526306 test_accuracy: ,0.8777173757553101\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3438304662704468 test_accuracy: ,0.8776041865348816\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3414621651172638 test_accuracy: ,0.8824999928474426\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3401133418083191 test_accuracy: ,0.8822115659713745\n",
            "epoch:  29 train_loss: ,0.4694764018058777 train_accuracy: ,0.7811447978019714 test_loss: ,0.3401794731616974 test_accuracy: ,0.8827751278877258\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3616900146007538 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.40154436230659485 test_accuracy: ,0.78125\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3887059688568115 test_accuracy: ,0.8333333134651184\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.36731404066085815 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3679749071598053 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.36766839027404785 test_accuracy: ,0.8645833134651184\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3490239977836609 test_accuracy: ,0.8839285969734192\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3403599262237549 test_accuracy: ,0.890625\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.34598028659820557 test_accuracy: ,0.8819444179534912\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3409963548183441 test_accuracy: ,0.8812500238418579\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3383001387119293 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.36418235301971436 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.368367999792099 test_accuracy: ,0.870192289352417\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.36765483021736145 test_accuracy: ,0.875\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3623720407485962 test_accuracy: ,0.8791666626930237\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3556884825229645 test_accuracy: ,0.8828125\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.34796908497810364 test_accuracy: ,0.8860294222831726\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3464069962501526 test_accuracy: ,0.8888888955116272\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.34249982237815857 test_accuracy: ,0.8914473652839661\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3433348536491394 test_accuracy: ,0.890625\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3422340452671051 test_accuracy: ,0.8928571343421936\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.33909597992897034 test_accuracy: ,0.8920454382896423\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3487307131290436 test_accuracy: ,0.885869562625885\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3465178310871124 test_accuracy: ,0.890625\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3400769829750061 test_accuracy: ,0.8949999809265137\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.3384760618209839 test_accuracy: ,0.8966346383094788\n",
            "epoch:  30 train_loss: ,0.47026652097702026 train_accuracy: ,0.7833894491195679 test_loss: ,0.33951371908187866 test_accuracy: ,0.8971291780471802\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.33849650621414185 test_accuracy: ,0.9375\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3742520809173584 test_accuracy: ,0.84375\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.35286882519721985 test_accuracy: ,0.875\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3515569865703583 test_accuracy: ,0.890625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3619071841239929 test_accuracy: ,0.887499988079071\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3515673577785492 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3408834636211395 test_accuracy: ,0.9107142686843872\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.32265257835388184 test_accuracy: ,0.9140625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3336624503135681 test_accuracy: ,0.9027777910232544\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3327397406101227 test_accuracy: ,0.8999999761581421\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.31970006227493286 test_accuracy: ,0.9090909361839294\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3439473807811737 test_accuracy: ,0.9114583134651184\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3512569069862366 test_accuracy: ,0.9086538553237915\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.35216155648231506 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3516184985637665 test_accuracy: ,0.9083333611488342\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.34653744101524353 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.34357380867004395 test_accuracy: ,0.904411792755127\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3392678499221802 test_accuracy: ,0.9097222089767456\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3358214795589447 test_accuracy: ,0.9111841917037964\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.33538004755973816 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3316654562950134 test_accuracy: ,0.9077380895614624\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3272126019001007 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.32918691635131836 test_accuracy: ,0.904891312122345\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3333137333393097 test_accuracy: ,0.90625\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.3291690945625305 test_accuracy: ,0.9100000262260437\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.32696545124053955 test_accuracy: ,0.9086538553237915\n",
            "epoch:  31 train_loss: ,0.4568764865398407 train_accuracy: ,0.7957351207733154 test_loss: ,0.33247554302215576 test_accuracy: ,0.9090909361839294\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.2592872381210327 test_accuracy: ,0.9375\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.40486907958984375 test_accuracy: ,0.8125\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3438694477081299 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.32696259021759033 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.35667315125465393 test_accuracy: ,0.862500011920929\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.36547625064849854 test_accuracy: ,0.8645833134651184\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3455314338207245 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.32985857129096985 test_accuracy: ,0.8828125\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3262427747249603 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3234748840332031 test_accuracy: ,0.8812500238418579\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.33118632435798645 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.35792076587677 test_accuracy: ,0.8802083134651184\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3604912757873535 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.36379051208496094 test_accuracy: ,0.8705357313156128\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.36088424921035767 test_accuracy: ,0.8708333373069763\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.356192946434021 test_accuracy: ,0.87109375\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.34958964586257935 test_accuracy: ,0.8713235259056091\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3400823473930359 test_accuracy: ,0.8784722089767456\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3425242006778717 test_accuracy: ,0.8815789222717285\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.34325870871543884 test_accuracy: ,0.875\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3392658829689026 test_accuracy: ,0.8809523582458496\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3366149067878723 test_accuracy: ,0.8806818127632141\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.34366777539253235 test_accuracy: ,0.8804348111152649\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3406292498111725 test_accuracy: ,0.8828125\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3383564352989197 test_accuracy: ,0.8849999904632568\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3339548408985138 test_accuracy: ,0.8894230723381042\n",
            "epoch:  32 train_loss: ,0.45314261317253113 train_accuracy: ,0.7957351207733154 test_loss: ,0.3385155498981476 test_accuracy: ,0.8875598311424255\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3839194178581238 test_accuracy: ,0.75\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.35555848479270935 test_accuracy: ,0.8125\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3307516872882843 test_accuracy: ,0.8541666865348816\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.32925114035606384 test_accuracy: ,0.875\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3456135392189026 test_accuracy: ,0.8500000238418579\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3479710519313812 test_accuracy: ,0.8645833134651184\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3366033434867859 test_accuracy: ,0.8839285969734192\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3263717591762543 test_accuracy: ,0.890625\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3238038122653961 test_accuracy: ,0.8958333134651184\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.32193702459335327 test_accuracy: ,0.887499988079071\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3176722228527069 test_accuracy: ,0.8863636255264282\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.35091662406921387 test_accuracy: ,0.8854166865348816\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.351836234331131 test_accuracy: ,0.8846153616905212\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.34811028838157654 test_accuracy: ,0.8928571343421936\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3428635001182556 test_accuracy: ,0.8999999761581421\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.34071680903434753 test_accuracy: ,0.90625\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.33380916714668274 test_accuracy: ,0.904411792755127\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3296011686325073 test_accuracy: ,0.90625\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3315431773662567 test_accuracy: ,0.9078947305679321\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3310263752937317 test_accuracy: ,0.903124988079071\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3271101415157318 test_accuracy: ,0.9047619104385376\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.32608380913734436 test_accuracy: ,0.9005681872367859\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.33309125900268555 test_accuracy: ,0.9021739363670349\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.3298429250717163 test_accuracy: ,0.9036458134651184\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.32631945610046387 test_accuracy: ,0.9075000286102295\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.323999285697937 test_accuracy: ,0.9086538553237915\n",
            "epoch:  33 train_loss: ,0.45587825775146484 train_accuracy: ,0.7979797720909119 test_loss: ,0.32029709219932556 test_accuracy: ,0.9090909361839294\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3666069209575653 test_accuracy: ,0.875\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3512793183326721 test_accuracy: ,0.875\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3663040101528168 test_accuracy: ,0.8333333134651184\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3256511092185974 test_accuracy: ,0.875\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.33732151985168457 test_accuracy: ,0.862500011920929\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3470129072666168 test_accuracy: ,0.8645833134651184\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3351834714412689 test_accuracy: ,0.8839285969734192\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3248368799686432 test_accuracy: ,0.890625\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3133314847946167 test_accuracy: ,0.8958333134651184\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.31601303815841675 test_accuracy: ,0.893750011920929\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.31962525844573975 test_accuracy: ,0.8920454382896423\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.35030683875083923 test_accuracy: ,0.890625\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3462524712085724 test_accuracy: ,0.8894230723381042\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3461155295372009 test_accuracy: ,0.8928571343421936\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.33567649126052856 test_accuracy: ,0.8999999761581421\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.33520829677581787 test_accuracy: ,0.90234375\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3301870822906494 test_accuracy: ,0.904411792755127\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3300573229789734 test_accuracy: ,0.90625\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3324902057647705 test_accuracy: ,0.9046052694320679\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.33016377687454224 test_accuracy: ,0.903124988079071\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.32588472962379456 test_accuracy: ,0.898809552192688\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.32599544525146484 test_accuracy: ,0.9005681872367859\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3329678475856781 test_accuracy: ,0.9021739363670349\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.3293250501155853 test_accuracy: ,0.9036458134651184\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.32919514179229736 test_accuracy: ,0.9049999713897705\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.32416513562202454 test_accuracy: ,0.90625\n",
            "epoch:  34 train_loss: ,0.4572252333164215 train_accuracy: ,0.7946127653121948 test_loss: ,0.32503771781921387 test_accuracy: ,0.9066985845565796\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3196271061897278 test_accuracy: ,0.875\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3641834855079651 test_accuracy: ,0.8125\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.36073222756385803 test_accuracy: ,0.8125\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3412396311759949 test_accuracy: ,0.859375\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3492963910102844 test_accuracy: ,0.875\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.34847378730773926 test_accuracy: ,0.8854166865348816\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3292454183101654 test_accuracy: ,0.9017857313156128\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.32383543252944946 test_accuracy: ,0.90625\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.31408751010894775 test_accuracy: ,0.9097222089767456\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.32965800166130066 test_accuracy: ,0.893750011920929\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3193146586418152 test_accuracy: ,0.9034090638160706\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.34697553515434265 test_accuracy: ,0.90625\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3522292375564575 test_accuracy: ,0.8990384340286255\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3481714129447937 test_accuracy: ,0.8973214030265808\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.346828430891037 test_accuracy: ,0.8958333134651184\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3389868140220642 test_accuracy: ,0.90234375\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.33533501625061035 test_accuracy: ,0.904411792755127\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3304474353790283 test_accuracy: ,0.90625\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3294863700866699 test_accuracy: ,0.9111841917037964\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3285616934299469 test_accuracy: ,0.909375011920929\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.32163891196250916 test_accuracy: ,0.913690447807312\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.32302162051200867 test_accuracy: ,0.9090909361839294\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3306504786014557 test_accuracy: ,0.9103260636329651\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3284602761268616 test_accuracy: ,0.9114583134651184\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3243641257286072 test_accuracy: ,0.9150000214576721\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.3217509686946869 test_accuracy: ,0.9158653616905212\n",
            "epoch:  35 train_loss: ,0.4655441641807556 train_accuracy: ,0.7890011072158813 test_loss: ,0.31257539987564087 test_accuracy: ,0.9162679314613342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Titanic_model\")"
      ],
      "metadata": {
        "id": "xNr3ShObWfJH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"Titanic_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "542Ej2hsWyS5",
        "outputId": "6e175de5-fa12-4c8e-8fb5-f30fc64985ac"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}