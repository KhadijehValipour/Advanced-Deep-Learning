{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9VUCh4QsFQ5U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train =x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n"
      ],
      "metadata": {
        "id": "kyfcY9h1GSXq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHPVs92wIN1D",
        "outputId": "ed9b87ff-f6e2-490a-c574-a2b96fec7208"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train[0][1,1,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjVI4cjcIUbT",
        "outputId": "3fb918f0-fa7b-4953-af0a-82dedb0568a9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "metadata": {
        "id": "14k12OFzJ9f3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelMnist(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.d2(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = ModelMnist()\n",
        "\n"
      ],
      "metadata": {
        "id": "dUFKKQ48ZeXX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "hYw4g9JJi5rq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n"
      ],
      "metadata": {
        "id": "C-2Buzugmy3Q"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      pred_labels = model(images)\n",
        "      loss = loss_function(labels, pred_labels)\n",
        "    gradinets = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradinets, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, pred_labels)\n"
      ],
      "metadata": {
        "id": "8nE2vH2-zJD6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test(images, labels):\n",
        "    pred_labels = model(images)\n",
        "    loss = loss_function(labels, pred_labels)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(labels, pred_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "oJyC7IpEzsYR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 7\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  # train\n",
        "  for images, labels in train_dataset:\n",
        "    train(images, labels)\n",
        "\n",
        "\n",
        "  # test\n",
        "  for images, labels in test_dataset:\n",
        "    test(images, labels)\n",
        "\n",
        "    print(\"epoch:\",epoch + 1,\n",
        "          f\"Train Loss:, {train_loss.result()}\",\n",
        "          f\"Train Acc:, {train_accuracy.result()}\",\n",
        "          f\"Test Loss:, {test_loss.result()}\",\n",
        "          f\"Test Acc:, {test_accuracy.result()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Bp3m4jok19",
        "outputId": "e72283c1-eb47-407d-d981-86bbfd85667b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 3.175828169332817e-05 Test Acc:, 1.0\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 1.6283329387078993e-05 Test Acc:, 1.0\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 1.085803614842007e-05 Test Acc:, 1.0\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.009589306078851223 Test Acc:, 0.9921875\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.007671457715332508 Test Acc:, 0.9937499761581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.006392881274223328 Test Acc:, 0.9947916865348816\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.00549953430891037 Test Acc:, 0.9955357313156128\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.055864784866571426 Test Acc:, 0.9921875\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.049657586961984634 Test Acc:, 0.9930555820465088\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.04469182714819908 Test Acc:, 0.9937499761581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.16126900911331177 Test Acc:, 0.9886363744735718\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.14791236817836761 Test Acc:, 0.9895833134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.13653455674648285 Test Acc:, 0.9903846383094788\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19668075442314148 Test Acc:, 0.9888392686843872\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18360088765621185 Test Acc:, 0.9895833134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.17212583124637604 Test Acc:, 0.990234375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20383577048778534 Test Acc:, 0.9889705777168274\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19251155853271484 Test Acc:, 0.9895833134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24143962562084198 Test Acc:, 0.9884868264198303\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22936764359474182 Test Acc:, 0.989062488079071\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2187771499156952 Test Acc:, 0.9895833134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21037641167640686 Test Acc:, 0.9886363744735718\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23423127830028534 Test Acc:, 0.98777174949646\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2244717925786972 Test Acc:, 0.98828125\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21549291908740997 Test Acc:, 0.9887499809265137\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20720472931861877 Test Acc:, 0.989182710647583\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21702314913272858 Test Acc:, 0.9884259104728699\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2180832475423813 Test Acc:, 0.9866071343421936\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21056313812732697 Test Acc:, 0.9870689511299133\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2269454151391983 Test Acc:, 0.9854166507720947\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2250441014766693 Test Acc:, 0.9848790168762207\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27192696928977966 Test Acc:, 0.984375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2671842873096466 Test Acc:, 0.9839015007019043\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.25932592153549194 Test Acc:, 0.984375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.25480979681015015 Test Acc:, 0.9839285612106323\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2477317452430725 Test Acc:, 0.984375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24178537726402283 Test Acc:, 0.9839527010917664\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2354304939508438 Test Acc:, 0.984375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27607178688049316 Test Acc:, 0.9815705418586731\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2696092128753662 Test Acc:, 0.9820312261581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.263033390045166 Test Acc:, 0.9824694991111755\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27129489183425903 Test Acc:, 0.9821428656578064\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26498574018478394 Test Acc:, 0.9825581312179565\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28277674317359924 Test Acc:, 0.9822443127632141\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27691295742988586 Test Acc:, 0.9826388955116272\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2708930969238281 Test Acc:, 0.983016312122345\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.265129417181015 Test Acc:, 0.9833776354789734\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2731678783893585 Test Acc:, 0.9817708134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28337767720222473 Test Acc:, 0.9802296161651611\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27771010994911194 Test Acc:, 0.9806249737739563\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27226510643959045 Test Acc:, 0.9810048937797546\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26712095737457275 Test Acc:, 0.981370210647583\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27509504556655884 Test Acc:, 0.9811320900917053\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28237584233283997 Test Acc:, 0.9809027910232544\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27911797165870667 Test Acc:, 0.980681836605072\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2817337214946747 Test Acc:, 0.98046875\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2767910063266754 Test Acc:, 0.9808114171028137\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27282387018203735 Test Acc:, 0.9806034564971924\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.271192342042923 Test Acc:, 0.9804025292396545\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28490105271339417 Test Acc:, 0.979687511920929\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28023403882980347 Test Acc:, 0.9800204634666443\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2757267653942108 Test Acc:, 0.9803427457809448\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27136966586112976 Test Acc:, 0.980654776096344\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2810584008693695 Test Acc:, 0.97998046875\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2815176546573639 Test Acc:, 0.9798076748847961\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29015204310417175 Test Acc:, 0.9791666865348816\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.33914822340011597 Test Acc:, 0.9780783653259277\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3341607451438904 Test Acc:, 0.978400707244873\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3317050337791443 Test Acc:, 0.9778079986572266\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32696640491485596 Test Acc:, 0.9781249761581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3223612308502197 Test Acc:, 0.9784330725669861\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32901665568351746 Test Acc:, 0.9778645634651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32450971007347107 Test Acc:, 0.9781678318977356\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32012444734573364 Test Acc:, 0.978462815284729\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.320263147354126 Test Acc:, 0.9779166579246521\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.33011695742607117 Test Acc:, 0.9769737124443054\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32618793845176697 Test Acc:, 0.9768669009208679\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32426729798316956 Test Acc:, 0.9767628312110901\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32016265392303467 Test Acc:, 0.9770569801330566\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3161606192588806 Test Acc:, 0.977343738079071\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3122573792934418 Test Acc:, 0.977623462677002\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32084715366363525 Test Acc:, 0.9775152206420898\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3318741023540497 Test Acc:, 0.9774096608161926\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32792356610298157 Test Acc:, 0.9776785969734192\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3240656554698944 Test Acc:, 0.9779411554336548\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3237352967262268 Test Acc:, 0.9778342843055725\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32449471950531006 Test Acc:, 0.977729856967926\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3208072781562805 Test Acc:, 0.9779829382896423\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.31720271706581116 Test Acc:, 0.978230357170105\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.31367823481559753 Test Acc:, 0.9784722328186035\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3176754415035248 Test Acc:, 0.9783653616905212\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3293224275112152 Test Acc:, 0.977921187877655\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.33078715205192566 Test Acc:, 0.9774865508079529\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32802286744117737 Test Acc:, 0.977393627166748\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.32457005977630615 Test Acc:, 0.9776315689086914\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3221319615840912 Test Acc:, 0.9775390625\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3260749280452728 Test Acc:, 0.9774484634399414\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3227699398994446 Test Acc:, 0.9776785969734192\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3195096552371979 Test Acc:, 0.9779040217399597\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.31631454825401306 Test Acc:, 0.9781249761581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3131827116012573 Test Acc:, 0.9783415794372559\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3101122975349426 Test Acc:, 0.9785539507865906\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30959758162498474 Test Acc:, 0.9784587621688843\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30662065744400024 Test Acc:, 0.9786658883094788\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3049471080303192 Test Acc:, 0.9785714149475098\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3020702600479126 Test Acc:, 0.9787735939025879\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29924720525741577 Test Acc:, 0.9789719581604004\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30030304193496704 Test Acc:, 0.9788773059844971\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2975488305091858 Test Acc:, 0.9790710806846619\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2981281876564026 Test Acc:, 0.9789772629737854\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3046262562274933 Test Acc:, 0.9788851141929626\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3057541251182556 Test Acc:, 0.9787946343421936\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3034640848636627 Test Acc:, 0.9787057638168335\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3008021414279938 Test Acc:, 0.9788925647735596\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29818660020828247 Test Acc:, 0.979076087474823\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2956162095069885 Test Acc:, 0.9792564511299133\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29390719532966614 Test Acc:, 0.9791666865348816\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2945649027824402 Test Acc:, 0.9788135886192322\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29777440428733826 Test Acc:, 0.9784663915634155\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30454781651496887 Test Acc:, 0.9783853888511658\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30203184485435486 Test Acc:, 0.9785640239715576\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.3000746965408325 Test Acc:, 0.9784836173057556\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.30200737714767456 Test Acc:, 0.9784044623374939\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.300628662109375 Test Acc:, 0.9780746102333069\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2984367609024048 Test Acc:, 0.9779999852180481\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29607728123664856 Test Acc:, 0.97817462682724\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2937459647655487 Test Acc:, 0.9783464670181274\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29360663890838623 Test Acc:, 0.978271484375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29133060574531555 Test Acc:, 0.9784399271011353\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28908973932266235 Test Acc:, 0.9786057472229004\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2874899208545685 Test Acc:, 0.9785305261611938\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28740382194519043 Test Acc:, 0.978456437587738\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28919440507888794 Test Acc:, 0.9781485199928284\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29023468494415283 Test Acc:, 0.9780783653259277\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.29258713126182556 Test Acc:, 0.9780092835426331\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2904357612133026 Test Acc:, 0.9781709313392639\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2883167564868927 Test Acc:, 0.9783303141593933\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28624382615089417 Test Acc:, 0.9784873127937317\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28418728709220886 Test Acc:, 0.9786421060562134\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28215739130973816 Test Acc:, 0.9787946343421936\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.28135961294174194 Test Acc:, 0.978723406791687\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27944716811180115 Test Acc:, 0.9788732528686523\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27750077843666077 Test Acc:, 0.9790209531784058\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2755741775035858 Test Acc:, 0.9791666865348816\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27368009090423584 Test Acc:, 0.9793103337287903\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2735549807548523 Test Acc:, 0.9792380332946777\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2717099189758301 Test Acc:, 0.9793792366981506\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2698771357536316 Test Acc:, 0.9795185923576355\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27363139390945435 Test Acc:, 0.979446291923523\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27180716395378113 Test Acc:, 0.9795833230018616\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27811694145202637 Test Acc:, 0.9793046116828918\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2782275676727295 Test Acc:, 0.9792351722717285\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2764090895652771 Test Acc:, 0.9793708920478821\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27461424469947815 Test Acc:, 0.9795048832893372\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27284252643585205 Test Acc:, 0.979637086391449\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.27134793996810913 Test Acc:, 0.979567289352417\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26962175965309143 Test Acc:, 0.9796974658966064\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.267915278673172 Test Acc:, 0.9798259735107422\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2662302851676941 Test Acc:, 0.9799528121948242\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2645663619041443 Test Acc:, 0.9800781011581421\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26292309165000916 Test Acc:, 0.9802018404006958\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2619275152683258 Test Acc:, 0.9801311492919922\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26032060384750366 Test Acc:, 0.9802530407905579\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.25873327255249023 Test Acc:, 0.9803735017776489\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.25716519355773926 Test Acc:, 0.9804924130439758\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2556160092353821 Test Acc:, 0.9806099534034729\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.26190510392189026 Test Acc:, 0.9805389046669006\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2603461444377899 Test Acc:, 0.980654776096344\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.25880563259124756 Test Acc:, 0.9807692170143127\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2572832405567169 Test Acc:, 0.9808823466300964\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2557786703109741 Test Acc:, 0.9809941649436951\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2542915642261505 Test Acc:, 0.9811046719551086\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.252821683883667 Test Acc:, 0.9812138676643372\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2513687014579773 Test Acc:, 0.9813218116760254\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24993228912353516 Test Acc:, 0.9814285635948181\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24851225316524506 Test Acc:, 0.9815340638160706\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2492670863866806 Test Acc:, 0.9814618825912476\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24786688387393951 Test Acc:, 0.9815660119056702\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24648214876651764 Test Acc:, 0.981669008731842\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2451128214597702 Test Acc:, 0.9817708134651184\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24375860393047333 Test Acc:, 0.9818715453147888\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2424192726612091 Test Acc:, 0.9819711446762085\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24109457433223724 Test Acc:, 0.9820696711540222\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24036644399166107 Test Acc:, 0.9819973111152649\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2390671670436859 Test Acc:, 0.9820945858955383\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23779499530792236 Test Acc:, 0.9821908473968506\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24303199350833893 Test Acc:, 0.981951892375946\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24278584122657776 Test Acc:, 0.9817154407501221\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24233365058898926 Test Acc:, 0.9816468358039856\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24105824530124664 Test Acc:, 0.9817433953285217\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23981598019599915 Test Acc:, 0.9818390011787415\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23856693506240845 Test Acc:, 0.98193359375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.24009612202644348 Test Acc:, 0.9817033410072327\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23885850608348846 Test Acc:, 0.9817976951599121\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2376335859298706 Test Acc:, 0.9818910360336304\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23642118275165558 Test Acc:, 0.9819834232330322\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23522107303142548 Test Acc:, 0.9820748567581177\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23403307795524597 Test Acc:, 0.9821653962135315\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23285703361034393 Test Acc:, 0.9822550415992737\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23169274628162384 Test Acc:, 0.9823437333106995\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23054005205631256 Test Acc:, 0.9824315905570984\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22939877212047577 Test Acc:, 0.9825185537338257\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22826872766017914 Test Acc:, 0.9826046824455261\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22714975476264954 Test Acc:, 0.9826899766921997\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2268994152545929 Test Acc:, 0.982621967792511\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22875547409057617 Test Acc:, 0.9822512269020081\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2345479130744934 Test Acc:, 0.9820350408554077\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23431509733200073 Test Acc:, 0.9819711446762085\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23319397866725922 Test Acc:, 0.9820573925971985\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2320835292339325 Test Acc:, 0.9821428656578064\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2310830056667328 Test Acc:, 0.9822275042533875\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2349313646554947 Test Acc:, 0.981869101524353\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23382841050624847 Test Acc:, 0.9819542169570923\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23273615539073944 Test Acc:, 0.9820385575294495\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23165366053581238 Test Acc:, 0.9821220636367798\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.23063001036643982 Test Acc:, 0.9822048544883728\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22956719994544983 Test Acc:, 0.9822868704795837\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22851413488388062 Test Acc:, 0.9823681116104126\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22747069597244263 Test Acc:, 0.9824486374855042\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22643673419952393 Test Acc:, 0.9825283885002136\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22541213035583496 Test Acc:, 0.9826074838638306\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22439676523208618 Test Acc:, 0.9826858043670654\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22339050471782684 Test Acc:, 0.9827634692192078\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22239325940608978 Test Acc:, 0.9828404188156128\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22140483558177948 Test Acc:, 0.9829166531562805\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.22042518854141235 Test Acc:, 0.9829922318458557\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21945415437221527 Test Acc:, 0.9830671548843384\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21849164366722107 Test Acc:, 0.9831414222717285\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.217537522315979 Test Acc:, 0.9832150936126709\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2165917158126831 Test Acc:, 0.983288049697876\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21565409004688263 Test Acc:, 0.9833604097366333\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21472454071044922 Test Acc:, 0.9834321141242981\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21462924778461456 Test Acc:, 0.9833691120147705\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21371202170848846 Test Acc:, 0.9834401607513428\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21280260384082794 Test Acc:, 0.9835106134414673\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21190090477466583 Test Acc:, 0.9835805296897888\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21100680530071259 Test Acc:, 0.9836497902870178\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.21012023091316223 Test Acc:, 0.9837185144424438\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20924106240272522 Test Acc:, 0.9837865829467773\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20836922526359558 Test Acc:, 0.9838541746139526\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20750461518764496 Test Acc:, 0.9839211702346802\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20664715766906738 Test Acc:, 0.9839876294136047\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2057967633008957 Test Acc:, 0.9840534925460815\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20495332777500153 Test Acc:, 0.9841188788414001\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2041167914867401 Test Acc:, 0.984183669090271\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2032870501279831 Test Acc:, 0.9842479825019836\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.2024640291929245 Test Acc:, 0.9843117594718933\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20165298879146576 Test Acc:, 0.984375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20084314048290253 Test Acc:, 0.9844377636909485\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.20003975927829742 Test Acc:, 0.984499990940094\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19924280047416687 Test Acc:, 0.9845617413520813\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1984521746635437 Test Acc:, 0.9846230149269104\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19824433326721191 Test Acc:, 0.9845602512359619\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19746384024620056 Test Acc:, 0.9846210479736328\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19669097661972046 Test Acc:, 0.9846813678741455\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19592265784740448 Test Acc:, 0.9847412109375\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19516031444072723 Test Acc:, 0.9848005771636963\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19580161571502686 Test Acc:, 0.9847383499145508\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19504593312740326 Test Acc:, 0.9847972989082336\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1942957490682602 Test Acc:, 0.9848557710647583\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19358591735363007 Test Acc:, 0.9849137663841248\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19284704327583313 Test Acc:, 0.9849713444709778\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19213347136974335 Test Acc:, 0.9850285053253174\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19140568375587463 Test Acc:, 0.9850852489471436\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19068339467048645 Test Acc:, 0.9851415157318115\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1899665892124176 Test Acc:, 0.9851973652839661\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1908103972673416 Test Acc:, 0.9851357936859131\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19009841978549957 Test Acc:, 0.9851912260055542\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18939173221588135 Test Acc:, 0.9852463006973267\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18869028985500336 Test Acc:, 0.9853008985519409\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18799400329589844 Test Acc:, 0.9853551387786865\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1873028576374054 Test Acc:, 0.9854090213775635\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18661676347255707 Test Acc:, 0.9854624271392822\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18593567609786987 Test Acc:, 0.9855155348777771\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18525955080986023 Test Acc:, 0.9855681657791138\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18458832800388336 Test Acc:, 0.9856204986572266\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1839219331741333 Test Acc:, 0.9856723546981812\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18326035141944885 Test Acc:, 0.9857239127159119\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18260350823402405 Test Acc:, 0.9857751131057739\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1819513440132141 Test Acc:, 0.9858258962631226\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18130382895469666 Test Acc:, 0.9858763217926025\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.19022724032402039 Test Acc:, 0.9855939745903015\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18979714810848236 Test Acc:, 0.9855344295501709\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1891288459300995 Test Acc:, 0.9855853915214539\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18846523761749268 Test Acc:, 0.9856359362602234\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18780626356601715 Test Acc:, 0.985686182975769\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18715189397335052 Test Acc:, 0.985736072063446\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18650205433368683 Test Acc:, 0.9857856035232544\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18585672974586487 Test Acc:, 0.9858347773551941\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18521583080291748 Test Acc:, 0.9858835935592651\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18457935750484467 Test Acc:, 0.9859321117401123\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18394723534584045 Test Acc:, 0.9859803318977356\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18331943452358246 Test Acc:, 0.9860281348228455\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1826958954334259 Test Acc:, 0.9860756993293762\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1820765882730484 Test Acc:, 0.9861229062080383\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18146146833896637 Test Acc:, 0.9861697554588318\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18085047602653503 Test Acc:, 0.9862163066864014\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1802445352077484 Test Acc:, 0.9862625598907471\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1796417087316513 Test Acc:, 0.9863085150718689\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.17904290556907654 Test Acc:, 0.9863541722297668\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.17844808101654053 Test Acc:, 0.9863995313644409\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.17952273786067963 Test Acc:, 0.9862375855445862\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18277278542518616 Test Acc:, 0.985973596572876\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18217217922210693 Test Acc:, 0.9860197305679321\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18458832800388336 Test Acc:, 0.9859631061553955\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1873978078365326 Test Acc:, 0.9859068393707275\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18722055852413177 Test Acc:, 0.985850989818573\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18734972178936005 Test Acc:, 0.9857954382896423\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18674342334270477 Test Acc:, 0.9858414530754089\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18614445626735687 Test Acc:, 0.9858871102333069\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18554596602916718 Test Acc:, 0.985932469367981\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.1865272969007492 Test Acc:, 0.9858773946762085\n",
            "epoch: 1 Train Loss:, 5.563099633731916e-11 Train Acc:, 1.0 Test Loss:, 0.18593136966228485 Test Acc:, 0.9858999848365784\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 2.6297308068023995e-05 Test Acc:, 1.0\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 1.3591957213066053e-05 Test Acc:, 1.0\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 9.063788638741244e-06 Test Acc:, 1.0\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.010185489431023598 Test Acc:, 0.9921875\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.008148405700922012 Test Acc:, 0.9937499761581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.006790338084101677 Test Acc:, 0.9947916865348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.005841721780598164 Test Acc:, 0.9955357313156128\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.05654395744204521 Test Acc:, 0.9921875\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.05026129633188248 Test Acc:, 0.9930555820465088\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.04523516446352005 Test Acc:, 0.9937499761581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1613587737083435 Test Acc:, 0.9886363744735718\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.14799247682094574 Test Acc:, 0.9895833134651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.13660849630832672 Test Acc:, 0.9903846383094788\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19695155322551727 Test Acc:, 0.9888392686843872\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18385230004787445 Test Acc:, 0.9895833134651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.17236153781414032 Test Acc:, 0.990234375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20388108491897583 Test Acc:, 0.9889705777168274\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19255435466766357 Test Acc:, 0.9895833134651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2415170669555664 Test Acc:, 0.9884868264198303\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22944121062755585 Test Acc:, 0.989062488079071\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21881134808063507 Test Acc:, 0.9895833134651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21031180024147034 Test Acc:, 0.9886363744735718\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23423661291599274 Test Acc:, 0.98777174949646\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2244768887758255 Test Acc:, 0.98828125\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21549782156944275 Test Acc:, 0.9887499809265137\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20720943808555603 Test Acc:, 0.989182710647583\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21706143021583557 Test Acc:, 0.9884259104728699\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21808044612407684 Test Acc:, 0.9866071343421936\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21056044101715088 Test Acc:, 0.9870689511299133\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2267320603132248 Test Acc:, 0.9854166507720947\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22475895285606384 Test Acc:, 0.9848790168762207\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2718892991542816 Test Acc:, 0.984375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26712775230407715 Test Acc:, 0.9839015007019043\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2592710554599762 Test Acc:, 0.984375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2547152638435364 Test Acc:, 0.9839285612106323\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24763983488082886 Test Acc:, 0.984375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24173769354820251 Test Acc:, 0.9839527010917664\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23538456857204437 Test Acc:, 0.984375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2759335935115814 Test Acc:, 0.9815705418586731\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2694850564002991 Test Acc:, 0.9820312261581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2629122734069824 Test Acc:, 0.9824694991111755\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2712433338165283 Test Acc:, 0.9821428656578064\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26493537425994873 Test Acc:, 0.9825581312179565\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2827620804309845 Test Acc:, 0.9822443127632141\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27691662311553955 Test Acc:, 0.9826388955116272\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27089670300483704 Test Acc:, 0.983016312122345\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26513293385505676 Test Acc:, 0.9833776354789734\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27318063378334045 Test Acc:, 0.9817708134651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28347936272621155 Test Acc:, 0.9802296161651611\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2778097689151764 Test Acc:, 0.9806249737739563\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2723628282546997 Test Acc:, 0.9810048937797546\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26720860600471497 Test Acc:, 0.981370210647583\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2750200033187866 Test Acc:, 0.9811320900917053\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2823178768157959 Test Acc:, 0.9809027910232544\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27907654643058777 Test Acc:, 0.980681836605072\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28164973855018616 Test Acc:, 0.98046875\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2767085134983063 Test Acc:, 0.9808114171028137\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2726989686489105 Test Acc:, 0.9806034564971924\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2710968852043152 Test Acc:, 0.9804025292396545\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2849719226360321 Test Acc:, 0.979687511920929\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28030410408973694 Test Acc:, 0.9800204634666443\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27579498291015625 Test Acc:, 0.9803427457809448\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2714383602142334 Test Acc:, 0.980654776096344\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28104889392852783 Test Acc:, 0.97998046875\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28158754110336304 Test Acc:, 0.9798076748847961\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29014647006988525 Test Acc:, 0.9791666865348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.339108943939209 Test Acc:, 0.9780783653259277\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.33412203192710876 Test Acc:, 0.978400707244873\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.33170223236083984 Test Acc:, 0.9778079986572266\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3269636332988739 Test Acc:, 0.9781249761581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32235851883888245 Test Acc:, 0.9784330725669861\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3289016783237457 Test Acc:, 0.9778645634651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3243963122367859 Test Acc:, 0.9781678318977356\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32001256942749023 Test Acc:, 0.978462815284729\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.320090651512146 Test Acc:, 0.9783333539962769\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3298639953136444 Test Acc:, 0.9773848652839661\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3259773254394531 Test Acc:, 0.9772727489471436\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3239990174770355 Test Acc:, 0.9771634340286255\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.31989777088165283 Test Acc:, 0.9774525165557861\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3158990442752838 Test Acc:, 0.977734386920929\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.31199905276298523 Test Acc:, 0.9780092835426331\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3205653727054596 Test Acc:, 0.9778963327407837\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3315991759300232 Test Acc:, 0.977786123752594\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32765185832977295 Test Acc:, 0.9780505895614624\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3237971365451813 Test Acc:, 0.9783087968826294\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32345476746559143 Test Acc:, 0.9781976938247681\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32426920533180237 Test Acc:, 0.9780890941619873\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32058432698249817 Test Acc:, 0.9783380627632141\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.316982239484787 Test Acc:, 0.9785814881324768\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.31346023082733154 Test Acc:, 0.9788194298744202\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3174305260181427 Test Acc:, 0.978708803653717\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32904738187789917 Test Acc:, 0.97826087474823\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3304918706417084 Test Acc:, 0.9778226017951965\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3277098834514618 Test Acc:, 0.9777260422706604\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3242603838443756 Test Acc:, 0.9779605269432068\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32182931900024414 Test Acc:, 0.9778645634651184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.32579436898231506 Test Acc:, 0.9777706265449524\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3224909007549286 Test Acc:, 0.9779974222183228\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.31923341751098633 Test Acc:, 0.9782196879386902\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.31604108214378357 Test Acc:, 0.9784374833106995\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3129119575023651 Test Acc:, 0.9786509871482849\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3098441958427429 Test Acc:, 0.9788603186607361\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3093307912349701 Test Acc:, 0.978762149810791\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3063564598560333 Test Acc:, 0.9789663553237915\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.30466902256011963 Test Acc:, 0.9788690209388733\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.30179476737976074 Test Acc:, 0.979068398475647\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29897430539131165 Test Acc:, 0.9792640209197998\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3000434637069702 Test Acc:, 0.9791666865348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2972916066646576 Test Acc:, 0.9793577790260315\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2978675365447998 Test Acc:, 0.9792613387107849\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3043314218521118 Test Acc:, 0.9791666865348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.30541664361953735 Test Acc:, 0.9790736436843872\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3031313121318817 Test Acc:, 0.9789823293685913\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3004722595214844 Test Acc:, 0.9791666865348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2978595495223999 Test Acc:, 0.979347825050354\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2952919900417328 Test Acc:, 0.9795258641242981\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2936047613620758 Test Acc:, 0.9794337749481201\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29432567954063416 Test Acc:, 0.9790784120559692\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2976202964782715 Test Acc:, 0.9787290096282959\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3044474422931671 Test Acc:, 0.9786458611488342\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3019322454929352 Test Acc:, 0.9788222908973694\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29997801780700684 Test Acc:, 0.9787397384643555\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.301934152841568 Test Acc:, 0.9786585569381714\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.3006354868412018 Test Acc:, 0.9783266186714172\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29844170808792114 Test Acc:, 0.9782500267028809\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29608139395713806 Test Acc:, 0.9784226417541504\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2937500476837158 Test Acc:, 0.9785925149917603\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29365524649620056 Test Acc:, 0.978515625\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29137885570526123 Test Acc:, 0.9786821603775024\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.289137601852417 Test Acc:, 0.9788461327552795\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28755271434783936 Test Acc:, 0.978769063949585\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2874722480773926 Test Acc:, 0.9786931872367859\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28923189640045166 Test Acc:, 0.978383481502533\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2902924120426178 Test Acc:, 0.9783115386962891\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2926441729068756 Test Acc:, 0.9782407283782959\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.29049235582351685 Test Acc:, 0.978400707244873\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2883726954460144 Test Acc:, 0.9785584211349487\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.286296546459198 Test Acc:, 0.9787137508392334\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.28423959016799927 Test Acc:, 0.9788669347763062\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2822093069553375 Test Acc:, 0.9790178537368774\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2814042866230011 Test Acc:, 0.9789450168609619\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27948975563049316 Test Acc:, 0.9790933132171631\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27754294872283936 Test Acc:, 0.9792395234107971\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27561601996421814 Test Acc:, 0.9793837070465088\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.273722380399704 Test Acc:, 0.9795258641242981\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2735992670059204 Test Acc:, 0.9794520735740662\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27175575494766235 Test Acc:, 0.9795918464660645\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26992273330688477 Test Acc:, 0.9797297120094299\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27367573976516724 Test Acc:, 0.9796560406684875\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27185124158859253 Test Acc:, 0.9797916412353516\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2781602442264557 Test Acc:, 0.9795116186141968\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.278274804353714 Test Acc:, 0.9794408082962036\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2764560282230377 Test Acc:, 0.9795751571655273\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2746608555316925 Test Acc:, 0.9797077775001526\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.27288883924484253 Test Acc:, 0.9798387289047241\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2713944911956787 Test Acc:, 0.9797676205635071\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2696681618690491 Test Acc:, 0.9798964858055115\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26796141266822815 Test Acc:, 0.9800237417221069\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26627612113952637 Test Acc:, 0.9801493883132935\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2646118998527527 Test Acc:, 0.980273425579071\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2629683315753937 Test Acc:, 0.9803959727287292\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2619223892688751 Test Acc:, 0.9803240895271301\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26031550765037537 Test Acc:, 0.9804447889328003\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2587282061576843 Test Acc:, 0.9805639982223511\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.25716015696525574 Test Acc:, 0.980681836605072\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.25561100244522095 Test Acc:, 0.9807981848716736\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2618979215621948 Test Acc:, 0.9807260632514954\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.26033902168273926 Test Acc:, 0.980840802192688\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2587985396385193 Test Acc:, 0.9809541702270508\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2572762072086334 Test Acc:, 0.9810661673545837\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.255771666765213 Test Acc:, 0.9811769127845764\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2542846202850342 Test Acc:, 0.981286346912384\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.25281476974487305 Test Acc:, 0.9813945293426514\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.25136181712150574 Test Acc:, 0.9815014600753784\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24992544949054718 Test Acc:, 0.9816071391105652\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24850544333457947 Test Acc:, 0.9817116260528564\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24926024675369263 Test Acc:, 0.9816384315490723\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2478601336479187 Test Acc:, 0.9817415475845337\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2464754283428192 Test Acc:, 0.9818435907363892\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24510614573955536 Test Acc:, 0.9819444417953491\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24375197291374207 Test Acc:, 0.9820442199707031\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24241267144680023 Test Acc:, 0.9821428656578064\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24108801782131195 Test Acc:, 0.9822404384613037\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2403758466243744 Test Acc:, 0.98216712474823\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23907652497291565 Test Acc:, 0.9822635054588318\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23780366778373718 Test Acc:, 0.9823588728904724\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24300017952919006 Test Acc:, 0.9821189641952515\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2427445948123932 Test Acc:, 0.9818816781044006\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24227705597877502 Test Acc:, 0.9818121790885925\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2410019487142563 Test Acc:, 0.9819079041481018\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23975859582424164 Test Acc:, 0.9820026159286499\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23850984871387482 Test Acc:, 0.9820963740348816\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.24006526172161102 Test Acc:, 0.9818652868270874\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23882780969142914 Test Acc:, 0.9819587469100952\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2376030534505844 Test Acc:, 0.9820512533187866\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23639079928398132 Test Acc:, 0.9821428656578064\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23519083857536316 Test Acc:, 0.9822335243225098\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2340030074119568 Test Acc:, 0.9823232293128967\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2328271120786667 Test Acc:, 0.9824120402336121\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23166297376155853 Test Acc:, 0.9825000166893005\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2305104285478592 Test Acc:, 0.9825870394706726\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22936928272247314 Test Acc:, 0.9826732873916626\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22823938727378845 Test Acc:, 0.982758641242981\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2271205633878708 Test Acc:, 0.9828431606292725\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22687184810638428 Test Acc:, 0.9827743768692017\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22872158885002136 Test Acc:, 0.9824029207229614\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23453055322170258 Test Acc:, 0.9821860194206238\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23428767919540405 Test Acc:, 0.9821214079856873\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23316669464111328 Test Acc:, 0.9822069406509399\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2320563793182373 Test Acc:, 0.9822916388511658\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23105262219905853 Test Acc:, 0.9823756217956543\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.234937846660614 Test Acc:, 0.9820165038108826\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23383484780788422 Test Acc:, 0.9821009635925293\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.232742577791214 Test Acc:, 0.9821845889091492\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23166005313396454 Test Acc:, 0.982267439365387\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.23063556849956512 Test Acc:, 0.9823495149612427\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22957272827625275 Test Acc:, 0.9824308753013611\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22851964831352234 Test Acc:, 0.9825114607810974\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22747617959976196 Test Acc:, 0.9825913310050964\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22644220292568207 Test Acc:, 0.9826704263687134\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22541756927967072 Test Acc:, 0.9827488660812378\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22440217435359955 Test Acc:, 0.9828265905380249\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22339588403701782 Test Acc:, 0.9829035997390747\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22239862382411957 Test Acc:, 0.9829798936843872\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22141018509864807 Test Acc:, 0.9830555319786072\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.22043050825595856 Test Acc:, 0.9831305146217346\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2194594442844391 Test Acc:, 0.9832048416137695\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2184969037771225 Test Acc:, 0.9832785129547119\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21754276752471924 Test Acc:, 0.9833515286445618\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21659693121910095 Test Acc:, 0.9834238886833191\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21565929055213928 Test Acc:, 0.9834956526756287\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21472972631454468 Test Acc:, 0.9835668206214905\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21467070281505585 Test Acc:, 0.9835032224655151\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21375329792499542 Test Acc:, 0.9835737347602844\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21284371614456177 Test Acc:, 0.9836435914039612\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21194183826446533 Test Acc:, 0.983712911605835\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21104755997657776 Test Acc:, 0.983781635761261\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.21016080677509308 Test Acc:, 0.9838497638702393\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20928147435188293 Test Acc:, 0.9839173555374146\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20840947329998016 Test Acc:, 0.9839843511581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2075446993112564 Test Acc:, 0.9840508103370667\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2066870778799057 Test Acc:, 0.9841167330741882\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20583650469779968 Test Acc:, 0.9841821193695068\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20499292016029358 Test Acc:, 0.9842469096183777\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20415621995925903 Test Acc:, 0.9843112230300903\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20332631468772888 Test Acc:, 0.984375\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20250312983989716 Test Acc:, 0.9844382405281067\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2016921043395996 Test Acc:, 0.9845010042190552\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.20088209211826324 Test Acc:, 0.9845632314682007\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.2000785619020462 Test Acc:, 0.984624981880188\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19928143918514252 Test Acc:, 0.9846862554550171\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1984906941652298 Test Acc:, 0.984747052192688\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19825543463230133 Test Acc:, 0.9846838116645813\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1974749118089676 Test Acc:, 0.9847440719604492\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1967020034790039 Test Acc:, 0.9848039150238037\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19593364000320435 Test Acc:, 0.98486328125\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19517125189304352 Test Acc:, 0.9849221706390381\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1957990676164627 Test Acc:, 0.9848594665527344\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19504337012767792 Test Acc:, 0.984917938709259\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19429320096969604 Test Acc:, 0.9849759340286255\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19358190894126892 Test Acc:, 0.9850335121154785\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19284304976463318 Test Acc:, 0.9850906729698181\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19212904572486877 Test Acc:, 0.9851473569869995\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19140127301216125 Test Acc:, 0.9852036237716675\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19067901372909546 Test Acc:, 0.9852594137191772\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18996219336986542 Test Acc:, 0.9853148460388184\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1908157914876938 Test Acc:, 0.9852527976036072\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19010378420352936 Test Acc:, 0.9853078126907349\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18939708173274994 Test Acc:, 0.9853624701499939\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18869560956954956 Test Acc:, 0.9854166507720947\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18799932301044464 Test Acc:, 0.9854704737663269\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1873081475496292 Test Acc:, 0.9855238795280457\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1866220384836197 Test Acc:, 0.9855769276618958\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1859409362077713 Test Acc:, 0.9856295585632324\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18526478111743927 Test Acc:, 0.9856818318367004\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18459352850914001 Test Acc:, 0.985733687877655\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18392713367938995 Test Acc:, 0.985785186290741\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18326552212238312 Test Acc:, 0.9858363270759583\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18260864913463593 Test Acc:, 0.9858871102333069\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.181956484913826 Test Acc:, 0.9859374761581421\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18130895495414734 Test Acc:, 0.9859875440597534\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.19023087620735168 Test Acc:, 0.985704779624939\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18979665637016296 Test Acc:, 0.9856448769569397\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1891283541917801 Test Acc:, 0.9856954216957092\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18846474587917328 Test Acc:, 0.9857456088066101\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18780577182769775 Test Acc:, 0.9857954382896423\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18715140223503113 Test Acc:, 0.9858449697494507\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18650156259536743 Test Acc:, 0.9858940839767456\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18585623800754547 Test Acc:, 0.9859429001808167\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18521535396575928 Test Acc:, 0.985991358757019\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18457886576652527 Test Acc:, 0.9860395193099976\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18394675850868225 Test Acc:, 0.9860873222351074\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18331894278526306 Test Acc:, 0.9861348271369934\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1826954185962677 Test Acc:, 0.9861819744110107\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1820761114358902 Test Acc:, 0.9862288236618042\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18146099150180817 Test Acc:, 0.986275315284729\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18084999918937683 Test Acc:, 0.9863215684890747\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18024414777755737 Test Acc:, 0.9863674640655518\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.17964132130146027 Test Acc:, 0.9864130616188049\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1790425181388855 Test Acc:, 0.9864583611488342\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1784476935863495 Test Acc:, 0.9865033030509949\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.17947162687778473 Test Acc:, 0.9863410592079163\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1827297955751419 Test Acc:, 0.9860767126083374\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18212933838367462 Test Acc:, 0.9861225485801697\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18452057242393494 Test Acc:, 0.9860655665397644\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.1873108446598053 Test Acc:, 0.9860090017318726\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18715326488018036 Test Acc:, 0.9859527945518494\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18727251887321472 Test Acc:, 0.9858969449996948\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18666647374629974 Test Acc:, 0.985942542552948\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18606768548488617 Test Acc:, 0.9859879016876221\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18546943366527557 Test Acc:, 0.9860329627990723\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18643757700920105 Test Acc:, 0.9859775900840759\n",
            "epoch: 2 Train Loss:, 4.967053504612018e-11 Train Acc:, 1.0 Test Loss:, 0.18584193289279938 Test Acc:, 0.9860000014305115\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 3.257669959566556e-05 Test Acc:, 1.0\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 1.6714890080038458e-05 Test Acc:, 1.0\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 1.1146985343657434e-05 Test Acc:, 1.0\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.009726273827254772 Test Acc:, 0.9921875\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.00778103107586503 Test Acc:, 0.9937499761581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.006484192330390215 Test Acc:, 0.9947916865348816\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.005576303694397211 Test Acc:, 0.9955357313156128\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.05662860348820686 Test Acc:, 0.9921875\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.05033653602004051 Test Acc:, 0.9930555820465088\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.04530288279056549 Test Acc:, 0.9937499761581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.16198526322841644 Test Acc:, 0.9886363744735718\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.14857317507266998 Test Acc:, 0.9895833134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.137144535779953 Test Acc:, 0.9903846383094788\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19730563461780548 Test Acc:, 0.9888392686843872\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18418903648853302 Test Acc:, 0.9895833134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.17267721891403198 Test Acc:, 0.990234375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2041967660188675 Test Acc:, 0.9889705777168274\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19285249710083008 Test Acc:, 0.9895833134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24223092198371887 Test Acc:, 0.9884868264198303\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23011937737464905 Test Acc:, 0.989062488079071\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21945641934871674 Test Acc:, 0.9895833134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21101979911327362 Test Acc:, 0.9886363744735718\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23484456539154053 Test Acc:, 0.98777174949646\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22505950927734375 Test Acc:, 0.98828125\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21605712175369263 Test Acc:, 0.9887499809265137\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20774723589420319 Test Acc:, 0.989182710647583\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21756285429000854 Test Acc:, 0.9884259104728699\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21853092312812805 Test Acc:, 0.9866071343421936\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2109953761100769 Test Acc:, 0.9870689511299133\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22745998203754425 Test Acc:, 0.9854166507720947\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22572536766529083 Test Acc:, 0.9848790168762207\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27255547046661377 Test Acc:, 0.984375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.267865389585495 Test Acc:, 0.9839015007019043\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2599869966506958 Test Acc:, 0.984375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25542840361595154 Test Acc:, 0.9839285612106323\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2483331561088562 Test Acc:, 0.984375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24242934584617615 Test Acc:, 0.9839527010917664\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2360590398311615 Test Acc:, 0.984375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2767627537250519 Test Acc:, 0.9815705418586731\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27031582593917847 Test Acc:, 0.9820312261581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2637227773666382 Test Acc:, 0.9824694991111755\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27204060554504395 Test Acc:, 0.9821428656578064\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2657141089439392 Test Acc:, 0.9825581312179565\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28358954191207886 Test Acc:, 0.9822443127632141\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2777473032474518 Test Acc:, 0.9826388955116272\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2717093229293823 Test Acc:, 0.983016312122345\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2659282684326172 Test Acc:, 0.9833776354789734\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2740664482116699 Test Acc:, 0.9817708134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28433847427368164 Test Acc:, 0.9802296161651611\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2786516845226288 Test Acc:, 0.9806249737739563\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2731882333755493 Test Acc:, 0.9810048937797546\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.26801303029060364 Test Acc:, 0.981370210647583\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27596554160118103 Test Acc:, 0.9811320900917053\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28319212794303894 Test Acc:, 0.9809027910232544\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2799680233001709 Test Acc:, 0.980681836605072\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28257647156715393 Test Acc:, 0.98046875\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27761900424957275 Test Acc:, 0.9808114171028137\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.273612380027771 Test Acc:, 0.9806034564971924\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27200934290885925 Test Acc:, 0.9804025292396545\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2859620451927185 Test Acc:, 0.979687511920929\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2812774181365967 Test Acc:, 0.9800204634666443\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27675488591194153 Test Acc:, 0.9803427457809448\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2723776400089264 Test Acc:, 0.980654776096344\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2822015583515167 Test Acc:, 0.97998046875\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.282607764005661 Test Acc:, 0.9798076748847961\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2914382219314575 Test Acc:, 0.9791666865348816\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3405355215072632 Test Acc:, 0.9780783653259277\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3355276584625244 Test Acc:, 0.978400707244873\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.33304184675216675 Test Acc:, 0.9778079986572266\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3282841145992279 Test Acc:, 0.9781249761581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32366037368774414 Test Acc:, 0.9784330725669861\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.33028024435043335 Test Acc:, 0.9778645634651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3257559835910797 Test Acc:, 0.9781678318977356\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32135388255119324 Test Acc:, 0.978462815284729\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.321514368057251 Test Acc:, 0.9779166579246521\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3315681219100952 Test Acc:, 0.9769737124443054\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3276272416114807 Test Acc:, 0.9768669009208679\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3256791830062866 Test Acc:, 0.9767628312110901\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3215566575527191 Test Acc:, 0.9770569801330566\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.31753721833229065 Test Acc:, 0.977343738079071\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3136169910430908 Test Acc:, 0.977623462677002\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.322232186794281 Test Acc:, 0.9775152206420898\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3332953453063965 Test Acc:, 0.9774096608161926\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32932785153388977 Test Acc:, 0.9776785969734192\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32545340061187744 Test Acc:, 0.9779411554336548\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32513830065727234 Test Acc:, 0.9778342843055725\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32594120502471924 Test Acc:, 0.977729856967926\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3222373127937317 Test Acc:, 0.9779829382896423\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.31861668825149536 Test Acc:, 0.978230357170105\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3150765001773834 Test Acc:, 0.9784722328186035\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.319057434797287 Test Acc:, 0.9783653616905212\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.33069369196891785 Test Acc:, 0.977921187877655\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.33205968141555786 Test Acc:, 0.9774865508079529\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3292643427848816 Test Acc:, 0.977393627166748\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3257984519004822 Test Acc:, 0.9776315689086914\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3233613967895508 Test Acc:, 0.9775390625\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3273485004901886 Test Acc:, 0.9774484634399414\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32403111457824707 Test Acc:, 0.9776785969734192\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.32075807452201843 Test Acc:, 0.9779040217399597\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3175504803657532 Test Acc:, 0.9781249761581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3144064247608185 Test Acc:, 0.9783415794372559\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.31132400035858154 Test Acc:, 0.9785539507865906\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.31078386306762695 Test Acc:, 0.9784587621688843\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30779555439949036 Test Acc:, 0.9786658883094788\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30605220794677734 Test Acc:, 0.9785714149475098\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30316492915153503 Test Acc:, 0.9787735939025879\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30033165216445923 Test Acc:, 0.9789719581604004\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30139121413230896 Test Acc:, 0.9788773059844971\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2986268997192383 Test Acc:, 0.9790710806846619\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29922693967819214 Test Acc:, 0.9789772629737854\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.305606484413147 Test Acc:, 0.9788851141929626\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3068132698535919 Test Acc:, 0.9787946343421936\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30456778407096863 Test Acc:, 0.9787057638168335\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3018961548805237 Test Acc:, 0.9788925647735596\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2992711067199707 Test Acc:, 0.979076087474823\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29669132828712463 Test Acc:, 0.9792564511299133\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29497528076171875 Test Acc:, 0.9791666865348816\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29566341638565063 Test Acc:, 0.9788135886192322\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2989286184310913 Test Acc:, 0.9784663915634155\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30567577481269836 Test Acc:, 0.9783853888511658\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3031502366065979 Test Acc:, 0.9785640239715576\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.30119553208351135 Test Acc:, 0.9784836173057556\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3031378388404846 Test Acc:, 0.9784044623374939\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.3017105758190155 Test Acc:, 0.9780746102333069\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2995007336139679 Test Acc:, 0.9779999852180481\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29713383316993713 Test Acc:, 0.97817462682724\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2947942018508911 Test Acc:, 0.9783464670181274\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29463595151901245 Test Acc:, 0.978271484375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.29235196113586426 Test Acc:, 0.9784399271011353\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2901031970977783 Test Acc:, 0.9786057472229004\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2885061800479889 Test Acc:, 0.9785305261611938\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2884316146373749 Test Acc:, 0.978456437587738\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2902258038520813 Test Acc:, 0.9781485199928284\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2912956178188324 Test Acc:, 0.9780783653259277\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2936793565750122 Test Acc:, 0.9780092835426331\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2915199398994446 Test Acc:, 0.9781709313392639\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28939300775527954 Test Acc:, 0.9783303141593933\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2873152494430542 Test Acc:, 0.9784873127937317\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2852509021759033 Test Acc:, 0.9786421060562134\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28321340680122375 Test Acc:, 0.9787946343421936\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2824191749095917 Test Acc:, 0.978723406791687\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.28048619627952576 Test Acc:, 0.9788732528686523\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2785325348377228 Test Acc:, 0.9790209531784058\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27659884095191956 Test Acc:, 0.9791666865348816\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2746981978416443 Test Acc:, 0.9793103337287903\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27453944087028503 Test Acc:, 0.9792380332946777\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2726899981498718 Test Acc:, 0.9793792366981506\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27085092663764954 Test Acc:, 0.9795185923576355\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2745841443538666 Test Acc:, 0.979446291923523\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2727535665035248 Test Acc:, 0.9795833230018616\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27908268570899963 Test Acc:, 0.9793046116828918\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27913936972618103 Test Acc:, 0.9792351722717285\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2773149311542511 Test Acc:, 0.9793708920478821\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2755141854286194 Test Acc:, 0.9795048832893372\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2737366855144501 Test Acc:, 0.979637086391449\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.272240549325943 Test Acc:, 0.979567289352417\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.27050840854644775 Test Acc:, 0.9796974658966064\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2687963545322418 Test Acc:, 0.9798259735107422\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2671057879924774 Test Acc:, 0.9799528121948242\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2654363811016083 Test Acc:, 0.9800781011581421\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.26378771662712097 Test Acc:, 0.9802018404006958\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.26280027627944946 Test Acc:, 0.9801311492919922\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2611880302429199 Test Acc:, 0.9802530407905579\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2595953941345215 Test Acc:, 0.9803735017776489\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25802209973335266 Test Acc:, 0.9804924130439758\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2564677596092224 Test Acc:, 0.9806099534034729\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.26274505257606506 Test Acc:, 0.9805389046669006\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.261181116104126 Test Acc:, 0.980654776096344\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25963565707206726 Test Acc:, 0.9807692170143127\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25810837745666504 Test Acc:, 0.9808823466300964\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25659897923469543 Test Acc:, 0.9809941649436951\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2551071345806122 Test Acc:, 0.9811046719551086\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.253632515668869 Test Acc:, 0.9812138676643372\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.25217485427856445 Test Acc:, 0.9813218116760254\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2507338523864746 Test Acc:, 0.9814285635948181\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2493092566728592 Test Acc:, 0.9815340638160706\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2500283718109131 Test Acc:, 0.9814618825912476\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24862390756607056 Test Acc:, 0.9815660119056702\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24723494052886963 Test Acc:, 0.981669008731842\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24586144089698792 Test Acc:, 0.9817708134651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24450308084487915 Test Acc:, 0.9818715453147888\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24315966665744781 Test Acc:, 0.9819711446762085\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24183091521263123 Test Acc:, 0.9820696711540222\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24112172424793243 Test Acc:, 0.9819973111152649\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23981836438179016 Test Acc:, 0.9820945858955383\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23854108154773712 Test Acc:, 0.9821908473968506\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2437671273946762 Test Acc:, 0.981951892375946\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24348190426826477 Test Acc:, 0.9817154407501221\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24300342798233032 Test Acc:, 0.9816468358039856\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24172449111938477 Test Acc:, 0.9817433953285217\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.24047844111919403 Test Acc:, 0.9818390011787415\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23922593891620636 Test Acc:, 0.98193359375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2408168911933899 Test Acc:, 0.9817033410072327\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2395755797624588 Test Acc:, 0.9817976951599121\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23834697902202606 Test Acc:, 0.9818910360336304\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23713092505931854 Test Acc:, 0.9819834232330322\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23592720925807953 Test Acc:, 0.9820748567581177\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2347356677055359 Test Acc:, 0.9821653962135315\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2335560917854309 Test Acc:, 0.9822550415992737\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23238830268383026 Test Acc:, 0.9823437333106995\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.231232151389122 Test Acc:, 0.9824315905570984\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23008742928504944 Test Acc:, 0.9825185537338257\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2289540022611618 Test Acc:, 0.9826046824455261\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2278316766023636 Test Acc:, 0.9826899766921997\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22759361565113068 Test Acc:, 0.982621967792511\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22945040464401245 Test Acc:, 0.9822512269020081\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23525728285312653 Test Acc:, 0.9820350408554077\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23503020405769348 Test Acc:, 0.9819711446762085\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23390565812587738 Test Acc:, 0.9820573925971985\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23279182612895966 Test Acc:, 0.9821428656578064\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23179937899112701 Test Acc:, 0.9820793867111206\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23561832308769226 Test Acc:, 0.9817216992378235\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23451213538646698 Test Acc:, 0.9818075299263\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2334166020154953 Test Acc:, 0.9818925261497498\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23233094811439514 Test Acc:, 0.9819767475128174\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23130439221858978 Test Acc:, 0.9820601940155029\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.23023848235607147 Test Acc:, 0.9821428656578064\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22918233275413513 Test Acc:, 0.9822247624397278\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2281358391046524 Test Acc:, 0.9823059439659119\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22709886729717255 Test Acc:, 0.9823863506317139\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22607126832008362 Test Acc:, 0.9824660420417786\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22505292296409607 Test Acc:, 0.982545018196106\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22404372692108154 Test Acc:, 0.9826233386993408\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2230435609817505 Test Acc:, 0.9827008843421936\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22205226123332977 Test Acc:, 0.9827777743339539\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22106972336769104 Test Acc:, 0.9828540086746216\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.22009584307670593 Test Acc:, 0.982929527759552\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2191305160522461 Test Acc:, 0.9830043911933899\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21817360818386078 Test Acc:, 0.9830785989761353\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21722503006458282 Test Acc:, 0.9831521511077881\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21628466248512268 Test Acc:, 0.9832251071929932\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.215352401137352 Test Acc:, 0.9832974076271057\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21524456143379211 Test Acc:, 0.9832350015640259\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2143247127532959 Test Acc:, 0.9833066463470459\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21341268718242645 Test Acc:, 0.9833776354789734\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2125083953142166 Test Acc:, 0.9834480881690979\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21161173284053802 Test Acc:, 0.9835179448127747\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.21072261035442352 Test Acc:, 0.9835872054100037\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20984092354774475 Test Acc:, 0.9836558699607849\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20896658301353455 Test Acc:, 0.9837239384651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20809951424598694 Test Acc:, 0.9837914705276489\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20723959803581238 Test Acc:, 0.9838584661483765\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2063867598772049 Test Acc:, 0.983924925327301\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20554091036319733 Test Acc:, 0.9839907884597778\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2047019600868225 Test Acc:, 0.9840561151504517\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20386984944343567 Test Acc:, 0.9841209053993225\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20304445922374725 Test Acc:, 0.9841852188110352\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20223093032836914 Test Acc:, 0.9842489957809448\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.20141875743865967 Test Acc:, 0.9843122363090515\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.2006130814552307 Test Acc:, 0.984375\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1998138278722763 Test Acc:, 0.9844372272491455\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19902095198631287 Test Acc:, 0.9844990372657776\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19879651069641113 Test Acc:, 0.9844367504119873\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19801384210586548 Test Acc:, 0.9844980239868164\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1972385197877884 Test Acc:, 0.9845588207244873\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1964680552482605 Test Acc:, 0.984619140625\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19570358097553253 Test Acc:, 0.9846789836883545\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1963123381137848 Test Acc:, 0.9846172332763672\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1955546736717224 Test Acc:, 0.9846766591072083\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19480253756046295 Test Acc:, 0.9847355484962463\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19409304857254028 Test Acc:, 0.9847940802574158\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19335223734378815 Test Acc:, 0.9848520755767822\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19263817369937897 Test Acc:, 0.98490971326828\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19190849363803864 Test Acc:, 0.9849668741226196\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19118431210517883 Test Acc:, 0.985023558139801\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19046559929847717 Test Acc:, 0.9850798845291138\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19129841029644012 Test Acc:, 0.9850187301635742\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19058461487293243 Test Acc:, 0.9850746393203735\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18987610936164856 Test Acc:, 0.9851301312446594\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1891728788614273 Test Acc:, 0.9851852059364319\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18847481906414032 Test Acc:, 0.9852398633956909\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1877819001674652 Test Acc:, 0.9852941036224365\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.187094047665596 Test Acc:, 0.9853479862213135\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18641121685504913 Test Acc:, 0.985401451587677\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.185733363032341 Test Acc:, 0.9854545593261719\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18506041169166565 Test Acc:, 0.9855072498321533\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18439233303070068 Test Acc:, 0.9855595827102661\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18372905254364014 Test Acc:, 0.9856114983558655\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18307052552700043 Test Acc:, 0.9856630563735962\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18241669237613678 Test Acc:, 0.9857142567634583\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1817675232887268 Test Acc:, 0.9857650995254517\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1907176822423935 Test Acc:, 0.9854831695556641\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.19028550386428833 Test Acc:, 0.9854240417480469\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18961548805236816 Test Acc:, 0.9854753613471985\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18895018100738525 Test Acc:, 0.9855263233184814\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18828950822353363 Test Acc:, 0.9855769276618958\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1876334547996521 Test Acc:, 0.9856271743774414\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1869819462299347 Test Acc:, 0.9856770634651184\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18633495271205902 Test Acc:, 0.9857266545295715\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1856924146413803 Test Acc:, 0.985775887966156\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18505428731441498 Test Acc:, 0.9858247637748718\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18442054092884064 Test Acc:, 0.985873281955719\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1837911307811737 Test Acc:, 0.9859215021133423\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18316598236560822 Test Acc:, 0.9859693646430969\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18254508078098297 Test Acc:, 0.9860169291496277\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1819283813238144 Test Acc:, 0.9860641956329346\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1813158243894577 Test Acc:, 0.9861111044883728\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18070824444293976 Test Acc:, 0.9861577153205872\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1801038682460785 Test Acc:, 0.9862040281295776\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.17950351536273956 Test Acc:, 0.9862499833106995\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.17890715599060059 Test Acc:, 0.9862957000732422\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18000927567481995 Test Acc:, 0.9861341118812561\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1832466572523117 Test Acc:, 0.9858704805374146\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1826445311307907 Test Acc:, 0.9859169125556946\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18508397042751312 Test Acc:, 0.9858606457710266\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.1879168301820755 Test Acc:, 0.9858047366142273\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18772020936012268 Test Acc:, 0.9857491850852966\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18784292042255402 Test Acc:, 0.9856939911842346\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.187235027551651 Test Acc:, 0.9857403039932251\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18663442134857178 Test Acc:, 0.9857863187789917\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18603436648845673 Test Acc:, 0.9858319759368896\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18701918423175812 Test Acc:, 0.9857772588729858\n",
            "epoch: 3 Train Loss:, 5.7617820237165773e-11 Train Acc:, 1.0 Test Loss:, 0.18642167747020721 Test Acc:, 0.98580002784729\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 3.1416017009178177e-05 Test Acc:, 1.0\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 1.6112197045003995e-05 Test Acc:, 1.0\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 1.0743948223534971e-05 Test Acc:, 1.0\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.009453781880438328 Test Acc:, 0.9921875\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.007563038729131222 Test Acc:, 0.9937499761581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.006302532274276018 Test Acc:, 0.9947916865348816\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.005420636851340532 Test Acc:, 0.9955357313156128\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.05639664828777313 Test Acc:, 0.9921875\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.05013035237789154 Test Acc:, 0.9930555820465088\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.045117318630218506 Test Acc:, 0.9937499761581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1615832895040512 Test Acc:, 0.9886363744735718\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.14820703864097595 Test Acc:, 0.9895833134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.13680657744407654 Test Acc:, 0.9903846383094788\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1973145306110382 Test Acc:, 0.9888392686843872\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1841880977153778 Test Acc:, 0.9895833134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.17267633974552155 Test Acc:, 0.990234375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20449216663837433 Test Acc:, 0.9889705777168274\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1931314915418625 Test Acc:, 0.9895833134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24242837727069855 Test Acc:, 0.9884868264198303\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2303069531917572 Test Acc:, 0.989062488079071\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21966321766376495 Test Acc:, 0.9895833134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2111130803823471 Test Acc:, 0.9886363744735718\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23508526384830475 Test Acc:, 0.98777174949646\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22529016435146332 Test Acc:, 0.98828125\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2162785530090332 Test Acc:, 0.9887499809265137\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20796014368534088 Test Acc:, 0.989182710647583\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21781018376350403 Test Acc:, 0.9884259104728699\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.218828484416008 Test Acc:, 0.9866071343421936\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21128268539905548 Test Acc:, 0.9870689511299133\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22768738865852356 Test Acc:, 0.9854166507720947\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22583356499671936 Test Acc:, 0.9848790168762207\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2728751003742218 Test Acc:, 0.984375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26815831661224365 Test Acc:, 0.9839015007019043\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2602713108062744 Test Acc:, 0.984375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2556605339050293 Test Acc:, 0.9839285612106323\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2485588639974594 Test Acc:, 0.984375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24265512824058533 Test Acc:, 0.9839527010917664\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2362787127494812 Test Acc:, 0.984375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2772893011569977 Test Acc:, 0.9815705418586731\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2708389461040497 Test Acc:, 0.9820312261581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2642331123352051 Test Acc:, 0.9824694991111755\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27249670028686523 Test Acc:, 0.9821428656578064\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2661595940589905 Test Acc:, 0.9825581312179565\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2840974032878876 Test Acc:, 0.9822443127632141\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2782553434371948 Test Acc:, 0.9826388955116272\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27220630645751953 Test Acc:, 0.983016312122345\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26641467213630676 Test Acc:, 0.9833776354789734\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27429425716400146 Test Acc:, 0.9817708134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28457117080688477 Test Acc:, 0.9802296161651611\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2788797616958618 Test Acc:, 0.9806249737739563\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2734118402004242 Test Acc:, 0.9810048937797546\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2682364284992218 Test Acc:, 0.981370210647583\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27619796991348267 Test Acc:, 0.9811320900917053\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2834652364253998 Test Acc:, 0.9809027910232544\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28033411502838135 Test Acc:, 0.980681836605072\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2829146683216095 Test Acc:, 0.98046875\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27795127034187317 Test Acc:, 0.9808114171028137\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27397480607032776 Test Acc:, 0.9806034564971924\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2723552882671356 Test Acc:, 0.9804025292396545\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2862025201320648 Test Acc:, 0.979687511920929\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.281514048576355 Test Acc:, 0.9800204634666443\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2769865095615387 Test Acc:, 0.9803427457809448\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2726063132286072 Test Acc:, 0.980654776096344\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2822968065738678 Test Acc:, 0.97998046875\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28274232149124146 Test Acc:, 0.9798076748847961\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.29155442118644714 Test Acc:, 0.9791666865348816\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3408365845680237 Test Acc:, 0.9780783653259277\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.33582428097724915 Test Acc:, 0.978400707244873\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.33334025740623474 Test Acc:, 0.9778079986572266\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32857826352119446 Test Acc:, 0.9781249761581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3239504098892212 Test Acc:, 0.9784330725669861\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.33051997423171997 Test Acc:, 0.9778645634651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3259924352169037 Test Acc:, 0.9781678318977356\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32158711552619934 Test Acc:, 0.978462815284729\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32168933749198914 Test Acc:, 0.9779166579246521\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.33165445923805237 Test Acc:, 0.9769737124443054\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3277069330215454 Test Acc:, 0.9768669009208679\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32579684257507324 Test Acc:, 0.9767628312110901\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32167282700538635 Test Acc:, 0.9770569801330566\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3176519274711609 Test Acc:, 0.977343738079071\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.31373029947280884 Test Acc:, 0.977623462677002\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3223627507686615 Test Acc:, 0.9775152206420898\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3334945738315582 Test Acc:, 0.9774096608161926\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3295246958732605 Test Acc:, 0.9776785969734192\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3256479501724243 Test Acc:, 0.9779411554336548\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32531458139419556 Test Acc:, 0.9778342843055725\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32609227299690247 Test Acc:, 0.977729856967926\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3223866820335388 Test Acc:, 0.9779829382896423\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3187643587589264 Test Acc:, 0.978230357170105\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.31522253155708313 Test Acc:, 0.9784722328186035\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3191569447517395 Test Acc:, 0.9783653616905212\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.330840528011322 Test Acc:, 0.977921187877655\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3323157727718353 Test Acc:, 0.9774865508079529\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3295275866985321 Test Acc:, 0.977393627166748\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.326058954000473 Test Acc:, 0.9776315689086914\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32365697622299194 Test Acc:, 0.9775390625\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3277055025100708 Test Acc:, 0.9774484634399414\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3243838846683502 Test Acc:, 0.9776785969734192\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.32110726833343506 Test Acc:, 0.9779040217399597\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.31789618730545044 Test Acc:, 0.9781249761581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.31474870443344116 Test Acc:, 0.9783415794372559\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3116629421710968 Test Acc:, 0.9785539507865906\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.31114453077316284 Test Acc:, 0.9784587621688843\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3081527352333069 Test Acc:, 0.9786658883094788\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.30637216567993164 Test Acc:, 0.9785714149475098\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3034818768501282 Test Acc:, 0.9787735939025879\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3006456196308136 Test Acc:, 0.9789719581604004\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3017316162586212 Test Acc:, 0.9788773059844971\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2989642322063446 Test Acc:, 0.9790710806846619\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.29956310987472534 Test Acc:, 0.9789772629737854\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3059920370578766 Test Acc:, 0.9788851141929626\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3071683943271637 Test Acc:, 0.9787946343421936\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3049091696739197 Test Acc:, 0.9787057638168335\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3022345304489136 Test Acc:, 0.9788925647735596\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2996065020561218 Test Acc:, 0.979076087474823\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.29702383279800415 Test Acc:, 0.9792564511299133\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2953188717365265 Test Acc:, 0.9791666865348816\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.296010285615921 Test Acc:, 0.9788135886192322\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2993130385875702 Test Acc:, 0.9784663915634155\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3061133921146393 Test Acc:, 0.9783853888511658\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3035842180252075 Test Acc:, 0.9785640239715576\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3016059696674347 Test Acc:, 0.9784836173057556\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.3035860061645508 Test Acc:, 0.9784044623374939\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.30224451422691345 Test Acc:, 0.9780746102333069\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.30002710223197937 Test Acc:, 0.9779999852180481\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2976544201374054 Test Acc:, 0.97817462682724\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2953106760978699 Test Acc:, 0.9783464670181274\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2952020466327667 Test Acc:, 0.978271484375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.29291364550590515 Test Acc:, 0.9784399271011353\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2906605899333954 Test Acc:, 0.9786057472229004\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2890600264072418 Test Acc:, 0.9785305261611938\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2889605462551117 Test Acc:, 0.978456437587738\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2907848358154297 Test Acc:, 0.9781485199928284\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.29182955622673035 Test Acc:, 0.9780783653259277\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2942419648170471 Test Acc:, 0.9780092835426331\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2920784056186676 Test Acc:, 0.9781709313392639\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2899473011493683 Test Acc:, 0.9783303141593933\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28786417841911316 Test Acc:, 0.9784873127937317\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2857959270477295 Test Acc:, 0.9786421060562134\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28375452756881714 Test Acc:, 0.9787946343421936\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2829478085041046 Test Acc:, 0.978723406791687\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.28100982308387756 Test Acc:, 0.9788732528686523\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27905192971229553 Test Acc:, 0.9790209531784058\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27711454033851624 Test Acc:, 0.9791666865348816\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2752101719379425 Test Acc:, 0.9793103337287903\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2750382125377655 Test Acc:, 0.9792380332946777\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27318689227104187 Test Acc:, 0.9793792366981506\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2713438868522644 Test Acc:, 0.9795185923576355\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.275131493806839 Test Acc:, 0.979446291923523\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2732973098754883 Test Acc:, 0.9795833230018616\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2796558141708374 Test Acc:, 0.9793046116828918\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27970972657203674 Test Acc:, 0.9792351722717285\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27788156270980835 Test Acc:, 0.9793708920478821\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27607715129852295 Test Acc:, 0.9795048832893372\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27429601550102234 Test Acc:, 0.979637086391449\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2728055417537689 Test Acc:, 0.979567289352417\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.27106982469558716 Test Acc:, 0.9796974658966064\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2693541944026947 Test Acc:, 0.9798259735107422\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26766014099121094 Test Acc:, 0.9799528121948242\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2659872770309448 Test Acc:, 0.9800781011581421\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26433518528938293 Test Acc:, 0.9802018404006958\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.263317734003067 Test Acc:, 0.9801311492919922\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.261702299118042 Test Acc:, 0.9802530407905579\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26010656356811523 Test Acc:, 0.9803735017776489\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2585301399230957 Test Acc:, 0.9804924130439758\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2569727301597595 Test Acc:, 0.9806099534034729\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2632621228694916 Test Acc:, 0.9805389046669006\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.26169508695602417 Test Acc:, 0.980654776096344\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2601465880870819 Test Acc:, 0.9807692170143127\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2586163282394409 Test Acc:, 0.9808823466300964\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.25710394978523254 Test Acc:, 0.9809941649436951\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2556091547012329 Test Acc:, 0.9811046719551086\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.25413164496421814 Test Acc:, 0.9812138676643372\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.25267112255096436 Test Acc:, 0.9813218116760254\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2512272894382477 Test Acc:, 0.9814285635948181\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24979987740516663 Test Acc:, 0.9815340638160706\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.250518798828125 Test Acc:, 0.9814618825912476\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24911153316497803 Test Acc:, 0.9815660119056702\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24771985411643982 Test Acc:, 0.981669008731842\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24634365737438202 Test Acc:, 0.9817708134651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24498264491558075 Test Acc:, 0.9818715453147888\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2436365783214569 Test Acc:, 0.9819711446762085\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2423052340745926 Test Acc:, 0.9820696711540222\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2416089028120041 Test Acc:, 0.9819973111152649\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2403029203414917 Test Acc:, 0.9820945858955383\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23902097344398499 Test Acc:, 0.9821908473968506\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24426552653312683 Test Acc:, 0.981951892375946\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24399511516094208 Test Acc:, 0.9817154407501221\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24353022873401642 Test Acc:, 0.9816468358039856\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24224853515625 Test Acc:, 0.9817433953285217\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24100160598754883 Test Acc:, 0.9818390011787415\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23974639177322388 Test Acc:, 0.98193359375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24133211374282837 Test Acc:, 0.9817033410072327\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.24008813500404358 Test Acc:, 0.9817976951599121\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23885691165924072 Test Acc:, 0.9818910360336304\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23763826489448547 Test Acc:, 0.9819834232330322\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23643197119235992 Test Acc:, 0.9820748567581177\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23523786664009094 Test Acc:, 0.9821653962135315\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2340557724237442 Test Acc:, 0.9822550415992737\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23288549482822418 Test Acc:, 0.9823437333106995\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23172685503959656 Test Acc:, 0.9824315905570984\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2305797040462494 Test Acc:, 0.9825185537338257\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22944383323192596 Test Acc:, 0.9826046824455261\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22831910848617554 Test Acc:, 0.9826899766921997\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22806359827518463 Test Acc:, 0.982621967792511\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22993631660938263 Test Acc:, 0.9822512269020081\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2357194870710373 Test Acc:, 0.9820350408554077\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23547372221946716 Test Acc:, 0.9819711446762085\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23434706032276154 Test Acc:, 0.9820573925971985\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23323111236095428 Test Acc:, 0.9821428656578064\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23223531246185303 Test Acc:, 0.9820793867111206\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23608972132205963 Test Acc:, 0.9817216992378235\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23498132824897766 Test Acc:, 0.9818075299263\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23388364911079407 Test Acc:, 0.9818925261497498\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2327958196401596 Test Acc:, 0.9819767475128174\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2317575067281723 Test Acc:, 0.9820601940155029\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.23068949580192566 Test Acc:, 0.9821428656578064\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22963128983974457 Test Acc:, 0.9822247624397278\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2285827398300171 Test Acc:, 0.9823059439659119\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22754372656345367 Test Acc:, 0.9823863506317139\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22651411592960358 Test Acc:, 0.9824660420417786\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22549378871917725 Test Acc:, 0.982545018196106\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22448259592056274 Test Acc:, 0.9826233386993408\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2234804630279541 Test Acc:, 0.9827008843421936\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.222487211227417 Test Acc:, 0.9827777743339539\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22150278091430664 Test Acc:, 0.9828540086746216\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.22052699327468872 Test Acc:, 0.982929527759552\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21955977380275726 Test Acc:, 0.9830043911933899\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21860098838806152 Test Acc:, 0.9830785989761353\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21765054762363434 Test Acc:, 0.9831521511077881\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21670834720134735 Test Acc:, 0.9832251071929932\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21577425301074982 Test Acc:, 0.9832974076271057\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2156904637813568 Test Acc:, 0.9832350015640259\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21476870775222778 Test Acc:, 0.9833066463470459\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2138548046350479 Test Acc:, 0.9833776354789734\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21294863522052765 Test Acc:, 0.9834480881690979\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21205012500286102 Test Acc:, 0.9835179448127747\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21115915477275848 Test Acc:, 0.9835872054100037\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.21027563512325287 Test Acc:, 0.9836558699607849\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2093994915485382 Test Acc:, 0.9837239384651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20853061974048615 Test Acc:, 0.9837914705276489\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20766891539096832 Test Acc:, 0.9838584661483765\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20681431889533997 Test Acc:, 0.983924925327301\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20596671104431152 Test Acc:, 0.9839907884597778\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20512603223323822 Test Acc:, 0.9840561151504517\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2042921930551529 Test Acc:, 0.9841209053993225\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20346508920192719 Test Acc:, 0.9841852188110352\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.2026509940624237 Test Acc:, 0.9842489957809448\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20183713734149933 Test Acc:, 0.9843122363090515\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20102979242801666 Test Acc:, 0.984375\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.20022886991500854 Test Acc:, 0.9844372272491455\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1994343400001526 Test Acc:, 0.9844990372657776\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19922374188899994 Test Acc:, 0.9844367504119873\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19843938946723938 Test Acc:, 0.9844980239868164\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19766250252723694 Test Acc:, 0.9845588207244873\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19689038395881653 Test Acc:, 0.984619140625\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19612427055835724 Test Acc:, 0.9846789836883545\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1967451572418213 Test Acc:, 0.9846172332763672\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.195985808968544 Test Acc:, 0.9846766591072083\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19523201882839203 Test Acc:, 0.9847355484962463\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1945217102766037 Test Acc:, 0.9847940802574158\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19377927482128143 Test Acc:, 0.9848520755767822\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19306331872940063 Test Acc:, 0.98490971326828\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19233202934265137 Test Acc:, 0.9849668741226196\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19160623848438263 Test Acc:, 0.985023558139801\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19088594615459442 Test Acc:, 0.9850798845291138\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1917417049407959 Test Acc:, 0.9850187301635742\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1910262405872345 Test Acc:, 0.9850746393203735\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1903161108493805 Test Acc:, 0.9851301312446594\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18961124122142792 Test Acc:, 0.9851852059364319\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.188911572098732 Test Acc:, 0.9852398633956909\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18821704387664795 Test Acc:, 0.9852941036224365\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.187527596950531 Test Acc:, 0.9853479862213135\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18684318661689758 Test Acc:, 0.985401451587677\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1861637532711029 Test Acc:, 0.9854545593261719\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1854892522096634 Test Acc:, 0.9855072498321533\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18481962382793427 Test Acc:, 0.9855595827102661\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18415479362010956 Test Acc:, 0.9856114983558655\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18349474668502808 Test Acc:, 0.9856630563735962\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18283940851688385 Test Acc:, 0.9857142567634583\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1821887344121933 Test Acc:, 0.9857650995254517\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19114950299263 Test Acc:, 0.9854831695556641\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.19070760905742645 Test Acc:, 0.9854240417480469\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1900361031293869 Test Acc:, 0.9854753613471985\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1893693059682846 Test Acc:, 0.9855263233184814\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.188707172870636 Test Acc:, 0.9855769276618958\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18804965913295746 Test Acc:, 0.9856271743774414\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18739670515060425 Test Acc:, 0.9856770634651184\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18674828112125397 Test Acc:, 0.9857266545295715\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18610432744026184 Test Acc:, 0.985775887966156\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1854647845029831 Test Acc:, 0.9858247637748718\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18482963740825653 Test Acc:, 0.985873281955719\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18419881165027618 Test Acc:, 0.9859215021133423\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18357229232788086 Test Acc:, 0.9859693646430969\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1829500049352646 Test Acc:, 0.9860169291496277\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18233193457126617 Test Acc:, 0.9860641956329346\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18171802163124084 Test Acc:, 0.9861111044883728\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1811092495918274 Test Acc:, 0.9861577153205872\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18050353229045868 Test Acc:, 0.9862040281295776\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1799018532037735 Test Acc:, 0.9862499833106995\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.17930416762828827 Test Acc:, 0.9862957000732422\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18040010333061218 Test Acc:, 0.9861341118812561\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18365596234798431 Test Acc:, 0.9858704805374146\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18305259943008423 Test Acc:, 0.9859169125556946\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18546883761882782 Test Acc:, 0.9858606457710266\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18828465044498444 Test Acc:, 0.9858047366142273\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1881108433008194 Test Acc:, 0.9857491850852966\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18823744356632233 Test Acc:, 0.9856939911842346\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18762826919555664 Test Acc:, 0.9857403039932251\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.1870262324810028 Test Acc:, 0.9857863187789917\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18642491102218628 Test Acc:, 0.9858319759368896\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18739135563373566 Test Acc:, 0.9857772588729858\n",
            "epoch: 4 Train Loss:, 5.36441759069195e-11 Train Acc:, 1.0 Test Loss:, 0.18679265677928925 Test Acc:, 0.98580002784729\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 2.940912963822484e-05 Test Acc:, 1.0\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 1.511434129497502e-05 Test Acc:, 1.0\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 1.0078711056848988e-05 Test Acc:, 1.0\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.010870305821299553 Test Acc:, 0.9921875\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.008696259930729866 Test Acc:, 0.9937499761581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.007246883120387793 Test Acc:, 0.9947916865348816\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.006234387401491404 Test Acc:, 0.9955357313156128\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.0581190250813961 Test Acc:, 0.9921875\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.051661357283592224 Test Acc:, 0.9930555820465088\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.046495221555233 Test Acc:, 0.9937499761581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.16288262605667114 Test Acc:, 0.9886363744735718\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.14938884973526 Test Acc:, 0.9895833134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.13789747655391693 Test Acc:, 0.9903846383094788\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1982806921005249 Test Acc:, 0.9888392686843872\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18508955836296082 Test Acc:, 0.9895833134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.17352145910263062 Test Acc:, 0.990234375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2049444615840912 Test Acc:, 0.9889705777168274\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19355864822864532 Test Acc:, 0.9895833134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24281306564807892 Test Acc:, 0.9884868264198303\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23067240417003632 Test Acc:, 0.989062488079071\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2199823558330536 Test Acc:, 0.9895833134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21163703501224518 Test Acc:, 0.9886363744735718\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23570431768894196 Test Acc:, 0.98777174949646\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22588342428207397 Test Acc:, 0.98828125\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21684809029102325 Test Acc:, 0.9887499809265137\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20850777626037598 Test Acc:, 0.989182710647583\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21831007301807404 Test Acc:, 0.9884259104728699\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2191077619791031 Test Acc:, 0.9866071343421936\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21155232191085815 Test Acc:, 0.9870689511299133\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22795452177524567 Test Acc:, 0.9854166507720947\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2260911762714386 Test Acc:, 0.9848790168762207\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27323099970817566 Test Acc:, 0.984375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2685084044933319 Test Acc:, 0.9839015007019043\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26061108708381653 Test Acc:, 0.984375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2559945583343506 Test Acc:, 0.9839285612106323\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24888359010219574 Test Acc:, 0.984375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.243015319108963 Test Acc:, 0.9839527010917664\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23663008213043213 Test Acc:, 0.984375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27744418382644653 Test Acc:, 0.9815705418586731\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27101102471351624 Test Acc:, 0.9820312261581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26440098881721497 Test Acc:, 0.9824694991111755\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.272805780172348 Test Acc:, 0.9821428656578064\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26646149158477783 Test Acc:, 0.9825581312179565\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2844039499759674 Test Acc:, 0.9822443127632141\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2785494029521942 Test Acc:, 0.9826388955116272\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27249398827552795 Test Acc:, 0.983016312122345\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2666962444782257 Test Acc:, 0.9833776354789734\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2745904326438904 Test Acc:, 0.9817708134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2848733961582184 Test Acc:, 0.9802296161651611\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27917593717575073 Test Acc:, 0.9806249737739563\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2737022042274475 Test Acc:, 0.9810048937797546\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26851627230644226 Test Acc:, 0.981370210647583\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2761981189250946 Test Acc:, 0.9811320900917053\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2834714353084564 Test Acc:, 0.9809027910232544\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2803332507610321 Test Acc:, 0.980681836605072\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2828758656978607 Test Acc:, 0.98046875\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2779131531715393 Test Acc:, 0.9808114171028137\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27388161420822144 Test Acc:, 0.9806034564971924\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2723451256752014 Test Acc:, 0.9804025292396545\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2863408923149109 Test Acc:, 0.979687511920929\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2816503345966339 Test Acc:, 0.9800204634666443\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.277118444442749 Test Acc:, 0.9803427457809448\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2727406322956085 Test Acc:, 0.980654776096344\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2825748324394226 Test Acc:, 0.97998046875\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28311634063720703 Test Acc:, 0.9798076748847961\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29185256361961365 Test Acc:, 0.9791666865348816\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3410176932811737 Test Acc:, 0.9780783653259277\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3360027074813843 Test Acc:, 0.978400707244873\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33348599076271057 Test Acc:, 0.9778079986572266\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32872191071510315 Test Acc:, 0.9781249761581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3240920305252075 Test Acc:, 0.9784330725669861\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3304983079433441 Test Acc:, 0.9778645634651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3259710371494293 Test Acc:, 0.9781678318977356\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32156601548194885 Test Acc:, 0.978462815284729\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3216906487941742 Test Acc:, 0.9779166579246521\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3313535451889038 Test Acc:, 0.9769737124443054\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3274889886379242 Test Acc:, 0.9768669009208679\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32551372051239014 Test Acc:, 0.9767628312110901\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32139328122138977 Test Acc:, 0.9770569801330566\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31737586855888367 Test Acc:, 0.977343738079071\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3134576678276062 Test Acc:, 0.977623462677002\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3221396207809448 Test Acc:, 0.9775152206420898\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3332866132259369 Test Acc:, 0.9774096608161926\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32931917905807495 Test Acc:, 0.9776785969734192\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3254448473453522 Test Acc:, 0.9779411554336548\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32500869035720825 Test Acc:, 0.9778342843055725\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.325927197933197 Test Acc:, 0.977729856967926\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3222234845161438 Test Acc:, 0.9779829382896423\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3186030089855194 Test Acc:, 0.978230357170105\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3150629699230194 Test Acc:, 0.9784722328186035\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3190251588821411 Test Acc:, 0.9783653616905212\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3306276500225067 Test Acc:, 0.977921187877655\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33196166157722473 Test Acc:, 0.9774865508079529\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32914239168167114 Test Acc:, 0.977393627166748\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3256777822971344 Test Acc:, 0.9776315689086914\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3232642114162445 Test Acc:, 0.9775390625\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3272956907749176 Test Acc:, 0.9774484634399414\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32397329807281494 Test Acc:, 0.9776785969734192\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32070085406303406 Test Acc:, 0.9779040217399597\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31749382615089417 Test Acc:, 0.9781249761581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31435033679008484 Test Acc:, 0.9783415794372559\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31126847863197327 Test Acc:, 0.9785539507865906\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31076979637145996 Test Acc:, 0.9784587621688843\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3077816367149353 Test Acc:, 0.9786658883094788\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30603593587875366 Test Acc:, 0.9785714149475098\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3031488060951233 Test Acc:, 0.9787735939025879\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3003156781196594 Test Acc:, 0.9789719581604004\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30139878392219543 Test Acc:, 0.9788773059844971\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2986343801021576 Test Acc:, 0.9790710806846619\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29924604296684265 Test Acc:, 0.9789772629737854\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3056231439113617 Test Acc:, 0.9788851141929626\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30677905678749084 Test Acc:, 0.9787946343421936\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30453768372535706 Test Acc:, 0.9787057638168335\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3018662929534912 Test Acc:, 0.9788925647735596\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29924148321151733 Test Acc:, 0.979076087474823\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29666197299957275 Test Acc:, 0.9792564511299133\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2949868142604828 Test Acc:, 0.9791666865348816\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2957550287246704 Test Acc:, 0.9788135886192322\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29912692308425903 Test Acc:, 0.9784663915634155\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30592843890190125 Test Acc:, 0.9783853888511658\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3034006953239441 Test Acc:, 0.9785640239715576\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3014407753944397 Test Acc:, 0.9784836173057556\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3034355044364929 Test Acc:, 0.9784044623374939\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30211779475212097 Test Acc:, 0.9780746102333069\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29992082715034485 Test Acc:, 0.9779999852180481\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29754921793937683 Test Acc:, 0.97817462682724\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29520633816719055 Test Acc:, 0.9783464670181274\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2951439917087555 Test Acc:, 0.978271484375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2928560674190521 Test Acc:, 0.9784399271011353\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2906034290790558 Test Acc:, 0.9786057472229004\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28904008865356445 Test Acc:, 0.9785305261611938\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2889571189880371 Test Acc:, 0.978456437587738\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29075050354003906 Test Acc:, 0.9781485199928284\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2918454110622406 Test Acc:, 0.9780783653259277\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29427534341812134 Test Acc:, 0.9780092835426331\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2921115756034851 Test Acc:, 0.9781709313392639\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2899799346923828 Test Acc:, 0.9783303141593933\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28789249062538147 Test Acc:, 0.9784873127937317\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2858240008354187 Test Acc:, 0.9786421060562134\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28378239274024963 Test Acc:, 0.9787946343421936\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28297239542007446 Test Acc:, 0.978723406791687\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28102996945381165 Test Acc:, 0.9788732528686523\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2790721654891968 Test Acc:, 0.9790209531784058\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27713462710380554 Test Acc:, 0.9791666865348816\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27523067593574524 Test Acc:, 0.9793103337287903\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27508026361465454 Test Acc:, 0.9792380332946777\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27322953939437866 Test Acc:, 0.9793792366981506\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2713862359523773 Test Acc:, 0.9795185923576355\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27512219548225403 Test Acc:, 0.979446291923523\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2732880413532257 Test Acc:, 0.9795833230018616\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2796074450016022 Test Acc:, 0.9793046116828918\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27971747517585754 Test Acc:, 0.9792351722717285\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2778892517089844 Test Acc:, 0.9793708920478821\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2760847806930542 Test Acc:, 0.9795048832893372\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2743035852909088 Test Acc:, 0.979637086391449\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2728360593318939 Test Acc:, 0.979567289352417\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27110016345977783 Test Acc:, 0.9796974658966064\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26938432455062866 Test Acc:, 0.9798259735107422\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26769009232521057 Test Acc:, 0.9799528121948242\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26601701974868774 Test Acc:, 0.9800781011581421\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26436474919319153 Test Acc:, 0.9802018404006958\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2633024752140045 Test Acc:, 0.9801311492919922\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26168709993362427 Test Acc:, 0.9802530407905579\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2600914537906647 Test Acc:, 0.9803735017776489\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2585151493549347 Test Acc:, 0.9804924130439758\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2569578289985657 Test Acc:, 0.9806099534034729\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2632363438606262 Test Acc:, 0.9805389046669006\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26166945695877075 Test Acc:, 0.980654776096344\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26012110710144043 Test Acc:, 0.9807692170143127\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2585909962654114 Test Acc:, 0.9808823466300964\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25707876682281494 Test Acc:, 0.9809941649436951\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25558412075042725 Test Acc:, 0.9811046719551086\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2541067600250244 Test Acc:, 0.9812138676643372\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2526463568210602 Test Acc:, 0.9813218116760254\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25120267271995544 Test Acc:, 0.9814285635948181\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24977540969848633 Test Acc:, 0.9815340638160706\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25047990679740906 Test Acc:, 0.9814618825912476\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24907292425632477 Test Acc:, 0.9815660119056702\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24768145382404327 Test Acc:, 0.981669008731842\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2463054656982422 Test Acc:, 0.9817708134651184\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24494466185569763 Test Acc:, 0.9818715453147888\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2435988187789917 Test Acc:, 0.9819711446762085\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2422676682472229 Test Acc:, 0.9820696711540222\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2415980100631714 Test Acc:, 0.9819973111152649\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24029207229614258 Test Acc:, 0.9820945858955383\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.239011749625206 Test Acc:, 0.9821908473968506\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24417102336883545 Test Acc:, 0.981951892375946\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24389776587486267 Test Acc:, 0.9817154407501221\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24341197311878204 Test Acc:, 0.9816468358039856\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24213090538978577 Test Acc:, 0.9817433953285217\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24088037014007568 Test Acc:, 0.9818390011787415\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23962579667568207 Test Acc:, 0.98193359375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2412056028842926 Test Acc:, 0.9817033410072327\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23996227979660034 Test Acc:, 0.9817976951599121\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23873169720172882 Test Acc:, 0.9818910360336304\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2375136762857437 Test Acc:, 0.9819834232330322\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2363080233335495 Test Acc:, 0.9820748567581177\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23511454463005066 Test Acc:, 0.9821653962135315\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23393307626247406 Test Acc:, 0.9822550415992737\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.232763409614563 Test Acc:, 0.9823437333106995\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2316053807735443 Test Acc:, 0.9824315905570984\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2304588109254837 Test Acc:, 0.9825185537338257\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22932355105876923 Test Acc:, 0.9826046824455261\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22819942235946655 Test Acc:, 0.9826899766921997\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22794987261295319 Test Acc:, 0.982621967792511\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22978097200393677 Test Acc:, 0.9822512269020081\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23558750748634338 Test Acc:, 0.9820350408554077\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23533037304878235 Test Acc:, 0.9819711446762085\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23420439660549164 Test Acc:, 0.9820573925971985\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2330891340970993 Test Acc:, 0.9821428656578064\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2320786416530609 Test Acc:, 0.9822275042533875\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2359442412853241 Test Acc:, 0.981869101524353\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23483651876449585 Test Acc:, 0.9819542169570923\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23373955488204956 Test Acc:, 0.9820385575294495\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23265239596366882 Test Acc:, 0.9821220636367798\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23160937428474426 Test Acc:, 0.9822048544883728\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23054204881191254 Test Acc:, 0.9822868704795837\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22948452830314636 Test Acc:, 0.9823681116104126\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2284366488456726 Test Acc:, 0.9824486374855042\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22739830613136292 Test Acc:, 0.9825283885002136\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22636935114860535 Test Acc:, 0.9826074838638306\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22534966468811035 Test Acc:, 0.9826858043670654\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22433912754058838 Test Acc:, 0.9827634692192078\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22333765029907227 Test Acc:, 0.9828404188156128\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2223450392484665 Test Acc:, 0.9829166531562805\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22136123478412628 Test Acc:, 0.9829922318458557\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2203860729932785 Test Acc:, 0.9830671548843384\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.219419464468956 Test Acc:, 0.9831414222717285\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2184613049030304 Test Acc:, 0.9832150936126709\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21751146018505096 Test Acc:, 0.983288049697876\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21656985580921173 Test Acc:, 0.9833604097366333\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21563637256622314 Test Acc:, 0.9834321141242981\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2155756652355194 Test Acc:, 0.9833691120147705\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21465440094470978 Test Acc:, 0.9834401607513428\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2137409746646881 Test Acc:, 0.9835106134414673\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21283529698848724 Test Acc:, 0.9835805296897888\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21193726360797882 Test Acc:, 0.9836497902870178\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21104677021503448 Test Acc:, 0.9837185144424438\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21016372740268707 Test Acc:, 0.9837865829467773\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20928804576396942 Test Acc:, 0.9838541746139526\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20841962099075317 Test Acc:, 0.9839211702346802\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20755839347839355 Test Acc:, 0.9839876294136047\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.206704244017601 Test Acc:, 0.9840534925460815\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2058570832014084 Test Acc:, 0.9841188788414001\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2050168514251709 Test Acc:, 0.984183669090271\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2041834592819214 Test Acc:, 0.9842479825019836\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2033568024635315 Test Acc:, 0.9843117594718933\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20254220068454742 Test Acc:, 0.984375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20172877609729767 Test Acc:, 0.9844377636909485\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20092186331748962 Test Acc:, 0.984499990940094\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20012137293815613 Test Acc:, 0.9845617413520813\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.199327290058136 Test Acc:, 0.9846230149269104\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19909459352493286 Test Acc:, 0.9845602512359619\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1983107626438141 Test Acc:, 0.9846210479736328\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19753418862819672 Test Acc:, 0.9846813678741455\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1967625766992569 Test Acc:, 0.9847412109375\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1959969699382782 Test Acc:, 0.9848005771636963\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1965951919555664 Test Acc:, 0.9847383499145508\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1958363950252533 Test Acc:, 0.9847972989082336\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19508317112922668 Test Acc:, 0.9848557710647583\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19436928629875183 Test Acc:, 0.9849137663841248\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19362741708755493 Test Acc:, 0.9849713444709778\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19291161000728607 Test Acc:, 0.9850285053253174\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19218087196350098 Test Acc:, 0.9850852489471436\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1914556622505188 Test Acc:, 0.9851415157318115\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19073593616485596 Test Acc:, 0.9851973652839661\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19160331785678864 Test Acc:, 0.9851357936859131\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19088837504386902 Test Acc:, 0.9851912260055542\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1901787519454956 Test Acc:, 0.9852463006973267\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18947438895702362 Test Acc:, 0.9853008985519409\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1887752264738083 Test Acc:, 0.9853551387786865\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18808118999004364 Test Acc:, 0.9854090213775635\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1873922497034073 Test Acc:, 0.9854624271392822\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18670834600925446 Test Acc:, 0.9855155348777771\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18602940440177917 Test Acc:, 0.9855681657791138\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18535538017749786 Test Acc:, 0.9856204986572266\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18468622863292694 Test Acc:, 0.9856723546981812\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18402189016342163 Test Acc:, 0.9857239127159119\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18336230516433716 Test Acc:, 0.9857751131057739\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18270744383335114 Test Acc:, 0.9858258962631226\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1820572465658188 Test Acc:, 0.9858763217926025\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19099141657352448 Test Acc:, 0.9855939745903015\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19054141640663147 Test Acc:, 0.9855344295501709\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18987049162387848 Test Acc:, 0.9855853915214539\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18920429050922394 Test Acc:, 0.9856359362602234\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18854273855686188 Test Acc:, 0.985686182975769\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18788579106330872 Test Acc:, 0.985736072063446\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18723340332508087 Test Acc:, 0.9857856035232544\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18658554553985596 Test Acc:, 0.9858347773551941\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.185942143201828 Test Acc:, 0.9858835935592651\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18530316650867462 Test Acc:, 0.9859321117401123\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18466857075691223 Test Acc:, 0.9859803318977356\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18403829634189606 Test Acc:, 0.9860281348228455\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1834123134613037 Test Acc:, 0.9860756993293762\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1827905774116516 Test Acc:, 0.9861229062080383\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18217304348945618 Test Acc:, 0.9861697554588318\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18155966699123383 Test Acc:, 0.9862163066864014\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18095122277736664 Test Acc:, 0.9862625598907471\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1803460419178009 Test Acc:, 0.9863085150718689\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1797448843717575 Test Acc:, 0.9863541722297668\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.17914772033691406 Test Acc:, 0.9863995313644409\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1801767796278 Test Acc:, 0.9862375855445862\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18343111872673035 Test Acc:, 0.985973596572876\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18282851576805115 Test Acc:, 0.9860197305679321\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1852354258298874 Test Acc:, 0.9859631061553955\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18804170191287994 Test Acc:, 0.9859068393707275\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18788501620292664 Test Acc:, 0.985850989818573\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1880037784576416 Test Acc:, 0.9857954382896423\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1873953640460968 Test Acc:, 0.9858414530754089\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18679402768611908 Test Acc:, 0.9858871102333069\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18619345128536224 Test Acc:, 0.985932469367981\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18715494871139526 Test Acc:, 0.9858773946762085\n",
            "epoch: 5 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18655700981616974 Test Acc:, 0.9858999848365784\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 2.6218984203296714e-05 Test Acc:, 1.0\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 1.3603084880742244e-05 Test Acc:, 1.0\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 9.071206477528904e-06 Test Acc:, 1.0\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.009573758579790592 Test Acc:, 0.9921875\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.007659022696316242 Test Acc:, 0.9937499761581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.0063825189135968685 Test Acc:, 0.9947916865348816\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.005490479059517384 Test Acc:, 0.9955357313156128\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.05669593811035156 Test Acc:, 0.9921875\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.0503963902592659 Test Acc:, 0.9930555820465088\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.04535675048828125 Test Acc:, 0.9937499761581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.16143597662448883 Test Acc:, 0.9886363744735718\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.14807194471359253 Test Acc:, 0.9895833134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.13668186962604523 Test Acc:, 0.9903846383094788\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19704008102416992 Test Acc:, 0.9888392686843872\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18393783271312714 Test Acc:, 0.9895833134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.17244172096252441 Test Acc:, 0.990234375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20437078177928925 Test Acc:, 0.9889705777168274\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19301684200763702 Test Acc:, 0.9895833134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24233070015907288 Test Acc:, 0.9884868264198303\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2302141636610031 Test Acc:, 0.989062488079071\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2195429801940918 Test Acc:, 0.9895833134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21085263788700104 Test Acc:, 0.9886363744735718\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23498593270778656 Test Acc:, 0.98777174949646\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22519497573375702 Test Acc:, 0.98828125\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21618717908859253 Test Acc:, 0.9887499809265137\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20787228643894196 Test Acc:, 0.989182710647583\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21781432628631592 Test Acc:, 0.9884259104728699\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21902425587177277 Test Acc:, 0.9866071343421936\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21147169172763824 Test Acc:, 0.9870689511299133\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22805751860141754 Test Acc:, 0.9854166507720947\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22631949186325073 Test Acc:, 0.9848790168762207\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2734808623790741 Test Acc:, 0.984375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26873141527175903 Test Acc:, 0.9839015007019043\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26082754135131836 Test Acc:, 0.984375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25615981221199036 Test Acc:, 0.9839285612106323\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2490442544221878 Test Acc:, 0.984375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24315448105335236 Test Acc:, 0.9839527010917664\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23676718771457672 Test Acc:, 0.984375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2777821123600006 Test Acc:, 0.9815705418586731\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2713608741760254 Test Acc:, 0.9820312261581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26474234461784363 Test Acc:, 0.9824694991111755\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2730453908443451 Test Acc:, 0.9821428656578064\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2666955292224884 Test Acc:, 0.9825581312179565\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.28461840748786926 Test Acc:, 0.9822443127632141\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2787541449069977 Test Acc:, 0.9826388955116272\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27269428968429565 Test Acc:, 0.983016312122345\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26689228415489197 Test Acc:, 0.9833776354789734\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27487751841545105 Test Acc:, 0.9817708134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.28511154651641846 Test Acc:, 0.9802296161651611\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2794093191623688 Test Acc:, 0.9806249737739563\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27393102645874023 Test Acc:, 0.9810048937797546\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2687338888645172 Test Acc:, 0.981370210647583\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2766290605068207 Test Acc:, 0.9811320900917053\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2838836908340454 Test Acc:, 0.9809027910232544\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2807196378707886 Test Acc:, 0.980681836605072\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2832874655723572 Test Acc:, 0.98046875\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27831751108169556 Test Acc:, 0.9808114171028137\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27433016896247864 Test Acc:, 0.9806034564971924\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27268821001052856 Test Acc:, 0.9804025292396545\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2867186665534973 Test Acc:, 0.979687511920929\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2820214033126831 Test Acc:, 0.9800204634666443\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2774848937988281 Test Acc:, 0.9803427457809448\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27309930324554443 Test Acc:, 0.980654776096344\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2827248275279999 Test Acc:, 0.97998046875\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2831764817237854 Test Acc:, 0.9798076748847961\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29211199283599854 Test Acc:, 0.9791666865348816\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3414978086948395 Test Acc:, 0.9780783653259277\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.33647578954696655 Test Acc:, 0.978400707244873\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.333935022354126 Test Acc:, 0.9778079986572266\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3291645348072052 Test Acc:, 0.9781249761581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32452842593193054 Test Acc:, 0.9784330725669861\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3309765160083771 Test Acc:, 0.9778645634651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3264427185058594 Test Acc:, 0.9781678318977356\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32203131914138794 Test Acc:, 0.978462815284729\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32219013571739197 Test Acc:, 0.9779166579246521\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3322116434574127 Test Acc:, 0.9769737124443054\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.328264445066452 Test Acc:, 0.9768669009208679\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32635265588760376 Test Acc:, 0.9767628312110901\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3222216069698334 Test Acc:, 0.9770569801330566\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.31819385290145874 Test Acc:, 0.977343738079071\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.31426551938056946 Test Acc:, 0.977623462677002\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3227948844432831 Test Acc:, 0.9775152206420898\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3339465856552124 Test Acc:, 0.9774096608161926\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3299712538719177 Test Acc:, 0.9776785969734192\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3260892629623413 Test Acc:, 0.9779411554336548\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3257701098918915 Test Acc:, 0.9778342843055725\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32660073041915894 Test Acc:, 0.977729856967926\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3228893578052521 Test Acc:, 0.9779829382896423\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.319261372089386 Test Acc:, 0.978230357170105\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.315714031457901 Test Acc:, 0.9784722328186035\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.31969761848449707 Test Acc:, 0.9783653616905212\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.33138543367385864 Test Acc:, 0.977921187877655\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3328321576118469 Test Acc:, 0.9774865508079529\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3299923837184906 Test Acc:, 0.977393627166748\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32651886343955994 Test Acc:, 0.9776315689086914\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3241176903247833 Test Acc:, 0.9775390625\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3281581997871399 Test Acc:, 0.9774484634399414\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.32482782006263733 Test Acc:, 0.9776785969734192\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.321546733379364 Test Acc:, 0.9779040217399597\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3183312714099884 Test Acc:, 0.9781249761581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3151794672012329 Test Acc:, 0.9783415794372559\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3120894730091095 Test Acc:, 0.9785539507865906\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3115469515323639 Test Acc:, 0.9784587621688843\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3085513114929199 Test Acc:, 0.9786658883094788\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3067387640476227 Test Acc:, 0.9785714149475098\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.30384498834609985 Test Acc:, 0.9787735939025879\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.30100536346435547 Test Acc:, 0.9789719581604004\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3020799160003662 Test Acc:, 0.9788773059844971\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2993091940879822 Test Acc:, 0.9790710806846619\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29994434118270874 Test Acc:, 0.9789772629737854\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3062504529953003 Test Acc:, 0.9788851141929626\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3074414134025574 Test Acc:, 0.9787946343421936\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3051678538322449 Test Acc:, 0.9787057638168335\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3024909496307373 Test Acc:, 0.9788925647735596\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29986071586608887 Test Acc:, 0.979076087474823\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2972758710384369 Test Acc:, 0.9792564511299133\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2956027388572693 Test Acc:, 0.9791666865348816\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2963155508041382 Test Acc:, 0.9788135886192322\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29956409335136414 Test Acc:, 0.9784663915634155\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3063734769821167 Test Acc:, 0.9783853888511658\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3038419187068939 Test Acc:, 0.9785640239715576\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.3018396496772766 Test Acc:, 0.9784836173057556\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.30377647280693054 Test Acc:, 0.9784044623374939\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.30241814255714417 Test Acc:, 0.9780746102333069\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.30019548535346985 Test Acc:, 0.9779999852180481\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29782232642173767 Test Acc:, 0.97817462682724\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2954772710800171 Test Acc:, 0.9783464670181274\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.295364648103714 Test Acc:, 0.978271484375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29307499527931213 Test Acc:, 0.9784399271011353\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2908206582069397 Test Acc:, 0.9786057472229004\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2892540395259857 Test Acc:, 0.9785305261611938\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.28918081521987915 Test Acc:, 0.978456437587738\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.290966272354126 Test Acc:, 0.9781485199928284\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2920443117618561 Test Acc:, 0.9780783653259277\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.29443204402923584 Test Acc:, 0.9780092835426331\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2922670841217041 Test Acc:, 0.9781709313392639\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2901344895362854 Test Acc:, 0.9783303141593933\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.28805220127105713 Test Acc:, 0.9784873127937317\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2859831154346466 Test Acc:, 0.9786421060562134\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2839403748512268 Test Acc:, 0.9787946343421936\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.28315088152885437 Test Acc:, 0.978723406791687\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2812051475048065 Test Acc:, 0.9788732528686523\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27924472093582153 Test Acc:, 0.9790209531784058\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27730605006217957 Test Acc:, 0.9791666865348816\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2754010558128357 Test Acc:, 0.9793103337287903\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27522069215774536 Test Acc:, 0.9792380332946777\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27337032556533813 Test Acc:, 0.9793792366981506\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.271526575088501 Test Acc:, 0.9795185923576355\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2753324508666992 Test Acc:, 0.979446291923523\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2734968960285187 Test Acc:, 0.9795833230018616\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2798668444156647 Test Acc:, 0.9793046116828918\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2799379825592041 Test Acc:, 0.9792351722717285\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27810829877853394 Test Acc:, 0.9793708920478821\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27630239725112915 Test Acc:, 0.9795048832893372\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27451980113983154 Test Acc:, 0.979637086391449\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.27301380038261414 Test Acc:, 0.979567289352417\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2712770700454712 Test Acc:, 0.9796974658966064\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2695601284503937 Test Acc:, 0.9798259735107422\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26786479353904724 Test Acc:, 0.9799528121948242\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26619061827659607 Test Acc:, 0.9800781011581421\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2645372748374939 Test Acc:, 0.9802018404006958\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2635129988193512 Test Acc:, 0.9801311492919922\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2618963420391083 Test Acc:, 0.9802530407905579\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.260299414396286 Test Acc:, 0.9803735017776489\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25872185826301575 Test Acc:, 0.9804924130439758\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25716328620910645 Test Acc:, 0.9806099534034729\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26343610882759094 Test Acc:, 0.9805389046669006\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.26186805963516235 Test Acc:, 0.980654776096344\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2603185176849365 Test Acc:, 0.9807692170143127\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25878724455833435 Test Acc:, 0.9808823466300964\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2572738826274872 Test Acc:, 0.9809941649436951\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25577810406684875 Test Acc:, 0.9811046719551086\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2542996108531952 Test Acc:, 0.9812138676643372\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2528381049633026 Test Acc:, 0.9813218116760254\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.25139331817626953 Test Acc:, 0.9814285635948181\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24996496737003326 Test Acc:, 0.9815340638160706\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2506833076477051 Test Acc:, 0.9814618825912476\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2492751181125641 Test Acc:, 0.9815660119056702\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24788253009319305 Test Acc:, 0.981669008731842\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24650542438030243 Test Acc:, 0.9817708134651184\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24514351785182953 Test Acc:, 0.9818715453147888\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24379657208919525 Test Acc:, 0.9819711446762085\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2424643486738205 Test Acc:, 0.9820696711540222\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2417764663696289 Test Acc:, 0.9819973111152649\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2404695600271225 Test Acc:, 0.9820945858955383\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23918750882148743 Test Acc:, 0.9821908473968506\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24437424540519714 Test Acc:, 0.981951892375946\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2440798133611679 Test Acc:, 0.9817154407501221\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2436109036207199 Test Acc:, 0.9816468358039856\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24232877790927887 Test Acc:, 0.9817433953285217\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2410791963338852 Test Acc:, 0.9818390011787415\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.239823579788208 Test Acc:, 0.98193359375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24141591787338257 Test Acc:, 0.9817033410072327\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.24017150700092316 Test Acc:, 0.9817976951599121\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23893986642360687 Test Acc:, 0.9818910360336304\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.237720787525177 Test Acc:, 0.9819834232330322\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23651407659053802 Test Acc:, 0.9820748567581177\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23531955480575562 Test Acc:, 0.9821653962135315\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23413705825805664 Test Acc:, 0.9822550415992737\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2329663634300232 Test Acc:, 0.9823437333106995\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23180733621120453 Test Acc:, 0.9824315905570984\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23065976798534393 Test Acc:, 0.9825185537338257\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22952350974082947 Test Acc:, 0.9826046824455261\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.228398397564888 Test Acc:, 0.9826899766921997\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2281622737646103 Test Acc:, 0.982621967792511\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23003347218036652 Test Acc:, 0.9822512269020081\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2358468621969223 Test Acc:, 0.9820350408554077\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23561666905879974 Test Acc:, 0.9819711446762085\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.234489306807518 Test Acc:, 0.9820573925971985\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23337270319461823 Test Acc:, 0.9821428656578064\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2323645055294037 Test Acc:, 0.9822275042533875\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23621024191379547 Test Acc:, 0.981869101524353\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23510128259658813 Test Acc:, 0.9819542169570923\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23400303721427917 Test Acc:, 0.9820385575294495\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.23291464149951935 Test Acc:, 0.9821220636367798\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2318734973669052 Test Acc:, 0.9822048544883728\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2308049499988556 Test Acc:, 0.9822868704795837\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22974620759487152 Test Acc:, 0.9823681116104126\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22869715094566345 Test Acc:, 0.9824486374855042\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22765761613845825 Test Acc:, 0.9825283885002136\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22662748396396637 Test Acc:, 0.9826074838638306\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22560665011405945 Test Acc:, 0.9826858043670654\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22459495067596436 Test Acc:, 0.9827634692192078\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22359232604503632 Test Acc:, 0.9828404188156128\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2225985825061798 Test Acc:, 0.9829166531562805\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22161364555358887 Test Acc:, 0.9829922318458557\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.22063736617565155 Test Acc:, 0.9830671548843384\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2196696549654007 Test Acc:, 0.9831414222717285\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21871040761470795 Test Acc:, 0.9832150936126709\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21775949001312256 Test Acc:, 0.983288049697876\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21681681275367737 Test Acc:, 0.9833604097366333\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21588225662708282 Test Acc:, 0.9834321141242981\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21581712365150452 Test Acc:, 0.9833691120147705\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2148948311805725 Test Acc:, 0.9834401607513428\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21398037672042847 Test Acc:, 0.9835106134414673\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21307368576526642 Test Acc:, 0.9835805296897888\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21217463910579681 Test Acc:, 0.9836497902870178\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2112831473350525 Test Acc:, 0.9837185144424438\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.21039912104606628 Test Acc:, 0.9837865829467773\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20952245593070984 Test Acc:, 0.9838541746139526\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.208653062582016 Test Acc:, 0.9839211702346802\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20779086649417877 Test Acc:, 0.9839876294136047\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20693576335906982 Test Acc:, 0.9840534925460815\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20608766376972198 Test Acc:, 0.9841188788414001\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2052464783191681 Test Acc:, 0.984183669090271\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20441214740276337 Test Acc:, 0.9842479825019836\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20358456671237946 Test Acc:, 0.9843117594718933\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20276877284049988 Test Acc:, 0.984375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2019544392824173 Test Acc:, 0.9844377636909485\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.20114661753177643 Test Acc:, 0.984499990940094\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.2003452479839325 Test Acc:, 0.9845617413520813\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19955025613307953 Test Acc:, 0.9846230149269104\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19932103157043457 Test Acc:, 0.9845602512359619\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19853630661964417 Test Acc:, 0.9846210479736328\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19775868952274323 Test Acc:, 0.9846813678741455\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19698619842529297 Test Acc:, 0.9847412109375\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19621971249580383 Test Acc:, 0.9848005771636963\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.196809321641922 Test Acc:, 0.9847383499145508\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19604972004890442 Test Acc:, 0.9847972989082336\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19529569149017334 Test Acc:, 0.9848557710647583\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19458980858325958 Test Acc:, 0.9849137663841248\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19384710490703583 Test Acc:, 0.9849713444709778\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19312961399555206 Test Acc:, 0.9850285053253174\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1923980563879013 Test Acc:, 0.9850852489471436\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19167202711105347 Test Acc:, 0.9851415157318115\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19095149636268616 Test Acc:, 0.9851973652839661\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1918131709098816 Test Acc:, 0.9851357936859131\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1910974383354187 Test Acc:, 0.9851912260055542\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1903870403766632 Test Acc:, 0.9852463006973267\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18968190252780914 Test Acc:, 0.9853008985519409\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18898198008537292 Test Acc:, 0.9853551387786865\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1882871836423874 Test Acc:, 0.9854090213775635\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18759749829769135 Test Acc:, 0.9854624271392822\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18691283464431763 Test Acc:, 0.9855155348777771\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18623314797878265 Test Acc:, 0.9855681657791138\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18555839359760284 Test Acc:, 0.9856204986572266\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18488849699497223 Test Acc:, 0.9856723546981812\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18422342836856842 Test Acc:, 0.9857239127159119\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18356314301490784 Test Acc:, 0.9857751131057739\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18290755152702332 Test Acc:, 0.9858258962631226\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18225663900375366 Test Acc:, 0.9858763217926025\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.19119893014431 Test Acc:, 0.9855939745903015\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1907436102628708 Test Acc:, 0.9855344295501709\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1900719851255417 Test Acc:, 0.9855853915214539\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18940505385398865 Test Acc:, 0.9856359362602234\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18874280154705048 Test Acc:, 0.985686182975769\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1880851686000824 Test Acc:, 0.985736072063446\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18743209540843964 Test Acc:, 0.9857856035232544\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1867835372686386 Test Acc:, 0.9858347773551941\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18613944947719574 Test Acc:, 0.9858835935592651\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18549980223178864 Test Acc:, 0.9859321117401123\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18486452102661133 Test Acc:, 0.9859803318977356\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18423359096050262 Test Acc:, 0.9860281348228455\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18360695242881775 Test Acc:, 0.9860756993293762\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18298454582691193 Test Acc:, 0.9861229062080383\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18236635625362396 Test Acc:, 0.9861697554588318\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18175232410430908 Test Acc:, 0.9862163066864014\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18114331364631653 Test Acc:, 0.9862625598907471\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18053749203681946 Test Acc:, 0.9863085150718689\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.17993569374084473 Test Acc:, 0.9863541722297668\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.17933790385723114 Test Acc:, 0.9863995313644409\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18040840327739716 Test Acc:, 0.9862375855445862\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18364042043685913 Test Acc:, 0.985973596572876\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18303708732128143 Test Acc:, 0.9860197305679321\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1854669600725174 Test Acc:, 0.9859631061553955\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18827754259109497 Test Acc:, 0.9859068393707275\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18811161816120148 Test Acc:, 0.985850989818573\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1882323920726776 Test Acc:, 0.9857954382896423\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18762324750423431 Test Acc:, 0.9858414530754089\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.187020942568779 Test Acc:, 0.9858871102333069\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18641963601112366 Test Acc:, 0.985932469367981\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.1873839795589447 Test Acc:, 0.9858773946762085\n",
            "epoch: 6 Train Loss:, 4.172324638562763e-11 Train Acc:, 1.0 Test Loss:, 0.18678531050682068 Test Acc:, 0.9858999848365784\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 2.492332350811921e-05 Test Acc:, 1.0\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 1.299250652664341e-05 Test Acc:, 1.0\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 8.664154847792815e-06 Test Acc:, 1.0\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.00968714989721775 Test Acc:, 0.9921875\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.007749735377728939 Test Acc:, 0.9937499761581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.006458112969994545 Test Acc:, 0.9947916865348816\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.005553077440708876 Test Acc:, 0.9955357313156128\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.05711094290018082 Test Acc:, 0.9921875\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.05076528340578079 Test Acc:, 0.9930555820465088\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.04568875581026077 Test Acc:, 0.9937499761581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.16242003440856934 Test Acc:, 0.9886363744735718\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1489771455526352 Test Acc:, 0.9895833134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.13751743733882904 Test Acc:, 0.9903846383094788\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19814379513263702 Test Acc:, 0.9888392686843872\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18497300148010254 Test Acc:, 0.9895833134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.17341218888759613 Test Acc:, 0.990234375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2053380161523819 Test Acc:, 0.9889705777168274\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19393034279346466 Test Acc:, 0.9895833134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24352522194385529 Test Acc:, 0.9884868264198303\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23134896159172058 Test Acc:, 0.989062488079071\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22061292827129364 Test Acc:, 0.9895833134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21192342042922974 Test Acc:, 0.9886363744735718\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2360537201166153 Test Acc:, 0.98777174949646\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22621826827526093 Test Acc:, 0.98828125\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21716953814029694 Test Acc:, 0.9887499809265137\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20881685614585876 Test Acc:, 0.989182710647583\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21892057359218597 Test Acc:, 0.9884259104728699\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22020173072814941 Test Acc:, 0.9866071343421936\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21260856091976166 Test Acc:, 0.9870689511299133\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22918902337551117 Test Acc:, 0.9854166507720947\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22753891348838806 Test Acc:, 0.9848790168762207\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27480649948120117 Test Acc:, 0.984375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2699759006500244 Test Acc:, 0.9839015007019043\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26203542947769165 Test Acc:, 0.984375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2572634518146515 Test Acc:, 0.9839285612106323\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2501172423362732 Test Acc:, 0.984375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.244184672832489 Test Acc:, 0.9839527010917664\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23777234554290771 Test Acc:, 0.984375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2789633870124817 Test Acc:, 0.9815705418586731\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2724817991256714 Test Acc:, 0.9820312261581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2658359110355377 Test Acc:, 0.9824694991111755\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2742171883583069 Test Acc:, 0.9821428656578064\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26784005761146545 Test Acc:, 0.9825581312179565\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28581929206848145 Test Acc:, 0.9822443127632141\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2799544930458069 Test Acc:, 0.9826388955116272\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27386853098869324 Test Acc:, 0.983016312122345\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26804155111312866 Test Acc:, 0.9833776354789734\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27585628628730774 Test Acc:, 0.9817708134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2861110270023346 Test Acc:, 0.9802296161651611\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28038880228996277 Test Acc:, 0.9806249737739563\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2748912572860718 Test Acc:, 0.9810048937797546\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26967042684555054 Test Acc:, 0.981370210647583\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27758461236953735 Test Acc:, 0.9811320900917053\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28482261300086975 Test Acc:, 0.9809027910232544\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28174200654029846 Test Acc:, 0.980681836605072\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2843286693096161 Test Acc:, 0.98046875\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2793404459953308 Test Acc:, 0.9808114171028137\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2753254473209381 Test Acc:, 0.9806034564971924\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27377188205718994 Test Acc:, 0.9804025292396545\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2880227863788605 Test Acc:, 0.979687511920929\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28330370783805847 Test Acc:, 0.9800204634666443\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.278746634721756 Test Acc:, 0.9803427457809448\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2743372619152069 Test Acc:, 0.980654776096344\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28394296765327454 Test Acc:, 0.97998046875\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2843257486820221 Test Acc:, 0.9798076748847961\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29339009523391724 Test Acc:, 0.9791666865348816\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.34283360838890076 Test Acc:, 0.9780783653259277\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33779194951057434 Test Acc:, 0.978400707244873\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3352140784263611 Test Acc:, 0.9778079986572266\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33042532205581665 Test Acc:, 0.9781249761581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3257714509963989 Test Acc:, 0.9784330725669861\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33222973346710205 Test Acc:, 0.9778645634651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32767876982688904 Test Acc:, 0.9781678318977356\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3232506811618805 Test Acc:, 0.978462815284729\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3234378397464752 Test Acc:, 0.9779166579246521\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3336252272129059 Test Acc:, 0.9769737124443054\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3296515941619873 Test Acc:, 0.9768669009208679\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.327716201543808 Test Acc:, 0.9767628312110901\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3235678970813751 Test Acc:, 0.9770569801330566\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31952330470085144 Test Acc:, 0.977343738079071\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3155785799026489 Test Acc:, 0.977623462677002\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32413405179977417 Test Acc:, 0.9775152206420898\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3353462815284729 Test Acc:, 0.9774096608161926\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3313542902469635 Test Acc:, 0.9776785969734192\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.327455997467041 Test Acc:, 0.9779411554336548\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3271530866622925 Test Acc:, 0.9778342843055725\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3279869258403778 Test Acc:, 0.977729856967926\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32425978779792786 Test Acc:, 0.9779829382896423\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3206164240837097 Test Acc:, 0.978230357170105\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31705403327941895 Test Acc:, 0.9784722328186035\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32108014822006226 Test Acc:, 0.9783653616905212\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33276575803756714 Test Acc:, 0.977921187877655\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3341837227344513 Test Acc:, 0.9774865508079529\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.33133038878440857 Test Acc:, 0.977393627166748\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3278427720069885 Test Acc:, 0.9776315689086914\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32544779777526855 Test Acc:, 0.9775390625\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3295297622680664 Test Acc:, 0.9774484634399414\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.326183021068573 Test Acc:, 0.9776785969734192\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.32288825511932373 Test Acc:, 0.9779040217399597\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31965935230255127 Test Acc:, 0.9781249761581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3164944350719452 Test Acc:, 0.9783415794372559\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3133915364742279 Test Acc:, 0.9785539507865906\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.31280553340911865 Test Acc:, 0.9784587621688843\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3097977936267853 Test Acc:, 0.9786658883094788\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3079472482204437 Test Acc:, 0.9785714149475098\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3050420880317688 Test Acc:, 0.9787735939025879\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30219125747680664 Test Acc:, 0.9789719581604004\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30323517322540283 Test Acc:, 0.9788773059844971\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3004538118839264 Test Acc:, 0.9790710806846619\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3011036515235901 Test Acc:, 0.9789772629737854\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30738726258277893 Test Acc:, 0.9788851141929626\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30860528349876404 Test Acc:, 0.9787946343421936\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3063601851463318 Test Acc:, 0.9787057638168335\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30367282032966614 Test Acc:, 0.9788925647735596\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30103233456611633 Test Acc:, 0.979076087474823\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2984373867511749 Test Acc:, 0.9792564511299133\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29674121737480164 Test Acc:, 0.9791666865348816\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.297465980052948 Test Acc:, 0.9788135886192322\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3007553219795227 Test Acc:, 0.9784663915634155\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30753836035728455 Test Acc:, 0.9783853888511658\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30499714612960815 Test Acc:, 0.9785640239715576\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3029855787754059 Test Acc:, 0.9784836173057556\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30491963028907776 Test Acc:, 0.9784044623374939\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.30355656147003174 Test Acc:, 0.9780746102333069\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.3013201951980591 Test Acc:, 0.9779999852180481\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2989378869533539 Test Acc:, 0.97817462682724\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29658403992652893 Test Acc:, 0.9783464670181274\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2964668273925781 Test Acc:, 0.978271484375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.294168621301651 Test Acc:, 0.9784399271011353\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29190587997436523 Test Acc:, 0.9786057472229004\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29034900665283203 Test Acc:, 0.9785305261611938\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29026517271995544 Test Acc:, 0.978456437587738\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29203876852989197 Test Acc:, 0.9781485199928284\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2931249141693115 Test Acc:, 0.9780783653259277\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29552459716796875 Test Acc:, 0.9780092835426331\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2933516204357147 Test Acc:, 0.9781709313392639\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.29121115803718567 Test Acc:, 0.9783303141593933\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28912171721458435 Test Acc:, 0.9784873127937317\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28704503178596497 Test Acc:, 0.9786421060562134\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2849946916103363 Test Acc:, 0.9787946343421936\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2842143476009369 Test Acc:, 0.978723406791687\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28225693106651306 Test Acc:, 0.9788732528686523\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28028932213783264 Test Acc:, 0.9790209531784058\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27834343910217285 Test Acc:, 0.9791666865348816\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27643224596977234 Test Acc:, 0.9793103337287903\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2762318253517151 Test Acc:, 0.9792380332946777\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27437618374824524 Test Acc:, 0.9793792366981506\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27252528071403503 Test Acc:, 0.9795185923576355\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27632805705070496 Test Acc:, 0.979446291923523\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27448588609695435 Test Acc:, 0.9795833230018616\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2808753550052643 Test Acc:, 0.9793046116828918\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.28089800477027893 Test Acc:, 0.9792351722717285\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27906209230422974 Test Acc:, 0.9793708920478821\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2772499918937683 Test Acc:, 0.9795048832893372\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2754612863063812 Test Acc:, 0.979637086391449\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.27395230531692505 Test Acc:, 0.979567289352417\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2722093164920807 Test Acc:, 0.9796974658966064\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2704864740371704 Test Acc:, 0.9798259735107422\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.268785297870636 Test Acc:, 0.9799528121948242\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2671054005622864 Test Acc:, 0.9800781011581421\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26544633507728577 Test Acc:, 0.9802018404006958\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2644326090812683 Test Acc:, 0.9801311492919922\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2628103196620941 Test Acc:, 0.9802530407905579\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26120781898498535 Test Acc:, 0.9803735017776489\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25962474942207336 Test Acc:, 0.9804924130439758\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2580607235431671 Test Acc:, 0.9806099534034729\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26431772112846375 Test Acc:, 0.9805389046669006\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26274439692497253 Test Acc:, 0.980654776096344\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.26118969917297363 Test Acc:, 0.9807692170143127\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2596533000469208 Test Acc:, 0.9808823466300964\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2581348419189453 Test Acc:, 0.9809941649436951\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25663405656814575 Test Acc:, 0.9811046719551086\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2551506459712982 Test Acc:, 0.9812138676643372\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25368425250053406 Test Acc:, 0.9813218116760254\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25223463773727417 Test Acc:, 0.9814285635948181\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2508015036582947 Test Acc:, 0.9815340638160706\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25149616599082947 Test Acc:, 0.9814618825912476\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.25008341670036316 Test Acc:, 0.9815660119056702\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2486863136291504 Test Acc:, 0.981669008731842\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2473047524690628 Test Acc:, 0.9817708134651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24593842029571533 Test Acc:, 0.9818715453147888\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24458710849285126 Test Acc:, 0.9819711446762085\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24325056374073029 Test Acc:, 0.9820696711540222\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24258306622505188 Test Acc:, 0.9819973111152649\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24127180874347687 Test Acc:, 0.9820945858955383\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23998428881168365 Test Acc:, 0.9821908473968506\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24515335261821747 Test Acc:, 0.981951892375946\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24481743574142456 Test Acc:, 0.9817154407501221\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24432827532291412 Test Acc:, 0.9816468358039856\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24304237961769104 Test Acc:, 0.9817433953285217\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2417900264263153 Test Acc:, 0.9818390011787415\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24053071439266205 Test Acc:, 0.98193359375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2421855628490448 Test Acc:, 0.9817033410072327\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.24093718826770782 Test Acc:, 0.9817976951599121\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23970161378383636 Test Acc:, 0.9818910360336304\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2384786456823349 Test Acc:, 0.9819834232330322\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2372680902481079 Test Acc:, 0.9820748567581177\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23606976866722107 Test Acc:, 0.9821653962135315\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23488348722457886 Test Acc:, 0.9822550415992737\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23370906710624695 Test Acc:, 0.9823437333106995\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23254632949829102 Test Acc:, 0.9824315905570984\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23139511048793793 Test Acc:, 0.9825185537338257\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23025524616241455 Test Acc:, 0.9826046824455261\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22912654280662537 Test Acc:, 0.9826899766921997\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22888529300689697 Test Acc:, 0.982621967792511\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2307477444410324 Test Acc:, 0.9822512269020081\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23658046126365662 Test Acc:, 0.9820350408554077\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23636339604854584 Test Acc:, 0.9819711446762085\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23523247241973877 Test Acc:, 0.9820573925971985\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23411230742931366 Test Acc:, 0.9821428656578064\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23310834169387817 Test Acc:, 0.9820793867111206\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23691906034946442 Test Acc:, 0.9817216992378235\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23580676317214966 Test Acc:, 0.9818075299263\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23470522463321686 Test Acc:, 0.9818925261497498\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23361356556415558 Test Acc:, 0.9819767475128174\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23256756365299225 Test Acc:, 0.9820601940155029\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23149581253528595 Test Acc:, 0.9821428656578064\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.23043391108512878 Test Acc:, 0.9822247624397278\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22938169538974762 Test Acc:, 0.9823059439659119\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2283390611410141 Test Acc:, 0.9823863506317139\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2273058444261551 Test Acc:, 0.9824660420417786\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22628194093704224 Test Acc:, 0.982545018196106\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.225267231464386 Test Acc:, 0.9826233386993408\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22426161170005798 Test Acc:, 0.9827008843421936\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2232648879289627 Test Acc:, 0.9827777743339539\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2222769856452942 Test Acc:, 0.9828540086746216\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.22129780054092407 Test Acc:, 0.982929527759552\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2203271985054016 Test Acc:, 0.9830043911933899\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21936506032943726 Test Acc:, 0.9830785989761353\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21841131150722504 Test Acc:, 0.9831521511077881\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21746580302715302 Test Acc:, 0.9832251071929932\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21652844548225403 Test Acc:, 0.9832974076271057\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21643561124801636 Test Acc:, 0.9832350015640259\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21551066637039185 Test Acc:, 0.9833066463470459\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21459360420703888 Test Acc:, 0.9833776354789734\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2136843055486679 Test Acc:, 0.9834480881690979\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21278268098831177 Test Acc:, 0.9835179448127747\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2118886411190033 Test Acc:, 0.9835872054100037\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21100208163261414 Test Acc:, 0.9836558699607849\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.21012289822101593 Test Acc:, 0.9837239384651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2092510312795639 Test Acc:, 0.9837914705276489\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2083863466978073 Test Acc:, 0.9838584661483765\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20752879977226257 Test Acc:, 0.983924925327301\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20667827129364014 Test Acc:, 0.9839907884597778\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20583468675613403 Test Acc:, 0.9840561151504517\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2049979567527771 Test Acc:, 0.9841209053993225\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20416800677776337 Test Acc:, 0.9841852188110352\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2033500075340271 Test Acc:, 0.9842489957809448\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20253333449363708 Test Acc:, 0.9843122363090515\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20172320306301117 Test Acc:, 0.984375\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.2009195238351822 Test Acc:, 0.9844372272491455\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.20012225210666656 Test Acc:, 0.9844990372657776\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19989168643951416 Test Acc:, 0.9844367504119873\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19910471141338348 Test Acc:, 0.9844980239868164\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19832482933998108 Test Acc:, 0.9845588207244873\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19755011796951294 Test Acc:, 0.984619140625\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1967814415693283 Test Acc:, 0.9846789836883545\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1973753571510315 Test Acc:, 0.9846172332763672\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.196613609790802 Test Acc:, 0.9846766591072083\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19585740566253662 Test Acc:, 0.9847355484962463\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19514469802379608 Test Acc:, 0.9847940802574158\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1943998634815216 Test Acc:, 0.9848520755767822\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19368083775043488 Test Acc:, 0.98490971326828\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19294719398021698 Test Acc:, 0.9849668741226196\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1922190934419632 Test Acc:, 0.985023558139801\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19149649143218994 Test Acc:, 0.9850798845291138\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19234968721866608 Test Acc:, 0.9850187301635742\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1916319578886032 Test Acc:, 0.9850746393203735\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19091957807540894 Test Acc:, 0.9851301312446594\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1902124583721161 Test Acc:, 0.9851852059364319\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18951056897640228 Test Acc:, 0.9852398633956909\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18881383538246155 Test Acc:, 0.9852941036224365\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1881222128868103 Test Acc:, 0.9853479862213135\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18743564188480377 Test Acc:, 0.985401451587677\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.186754047870636 Test Acc:, 0.9854545593261719\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18607740104198456 Test Acc:, 0.9855072498321533\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1854056417942047 Test Acc:, 0.9855595827102661\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18473872542381287 Test Acc:, 0.9856114983558655\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18407657742500305 Test Acc:, 0.9856630563735962\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1834191530942917 Test Acc:, 0.9857142567634583\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18276642262935638 Test Acc:, 0.9857650995254517\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1917119324207306 Test Acc:, 0.9854831695556641\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.19124427437782288 Test Acc:, 0.9854240417480469\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1905708909034729 Test Acc:, 0.9854753613471985\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18990221619606018 Test Acc:, 0.9855263233184814\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18923822045326233 Test Acc:, 0.9855769276618958\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18857885897159576 Test Acc:, 0.9856271743774414\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1879240721464157 Test Acc:, 0.9856770634651184\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1872738152742386 Test Acc:, 0.9857266545295715\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1866280436515808 Test Acc:, 0.985775887966156\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1859867125749588 Test Acc:, 0.9858247637748718\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18534976243972778 Test Acc:, 0.985873281955719\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18471717834472656 Test Acc:, 0.9859215021133423\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18408888578414917 Test Acc:, 0.9859693646430969\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18346485495567322 Test Acc:, 0.9860169291496277\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18284504115581512 Test Acc:, 0.9860641956329346\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1822293996810913 Test Acc:, 0.9861111044883728\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18161869049072266 Test Acc:, 0.9861577153205872\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18101125955581665 Test Acc:, 0.9862040281295776\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18040789663791656 Test Acc:, 0.9862499833106995\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.17980852723121643 Test Acc:, 0.9862957000732422\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1808883249759674 Test Acc:, 0.9861341118812561\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18414513766765594 Test Acc:, 0.9858704805374146\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1835402101278305 Test Acc:, 0.9859169125556946\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18597480654716492 Test Acc:, 0.9858606457710266\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1887953132390976 Test Acc:, 0.9858047366142273\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18862885236740112 Test Acc:, 0.9857491850852966\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18875917792320251 Test Acc:, 0.9856939911842346\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18814831972122192 Test Acc:, 0.9857403039932251\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1875445395708084 Test Acc:, 0.9857863187789917\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18694154918193817 Test Acc:, 0.9858319759368896\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.1879163384437561 Test Acc:, 0.9857772588729858\n",
            "epoch: 7 Train Loss:, 3.973642595522797e-11 Train Acc:, 1.0 Test Loss:, 0.18731597065925598 Test Acc:, 0.98580002784729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = cv2.imread(\"/content/images0.png\")\n",
        "plt.imshow(image)\n",
        "image = cv2.cvtColor(image,  cv2.COLOR_BGR2GRAY)\n",
        "# Height, width\n",
        "image = cv2.resize(image, (28,28))\n",
        "# add batch size\n",
        "image = image[tf.newaxis, ...]\n",
        "# add channel\n",
        "image = image[..., tf.newaxis]\n",
        "image = image.astype(\"float32\")\n",
        "# image.shape\n",
        "\n",
        "\n",
        "pred = model(image)\n",
        "result = np.argmax(pred)\n",
        "print(\"result: \", result )"
      ],
      "metadata": {
        "id": "Pt28u_Ykg50I",
        "outputId": "b00bd7c2-b870-4909-ea80-f7d705366391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result:  0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}